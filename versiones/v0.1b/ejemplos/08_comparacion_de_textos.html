
<!DOCTYPE html>

<html lang="es">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>8. Comparación de textos &#8212; documentación de ConTexto - 0.1</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/translations.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Índice" href="../genindex.html" />
    <link rel="search" title="Búsqueda" href="../search.html" />
    <link rel="next" title="Casos de uso" href="09_casos_de_uso.html" />
    <link rel="prev" title="7. Vectorización de textos" href="07_vectorizacion_de_textos.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/logo_2.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../seccion_introduccion.html">
  Introducción
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../seccion_instalacion.html">
  Instalación
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../seccion_ejemplos.html">
  Ejemplos
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../seccion_lenguajes_soportados.html">
  Lenguajes soportados
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../seccion_ocr.html">
  OCR
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../funciones/comparacion.html">
  Comparación
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../funciones/correccion.html">
  Corrección
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../funciones/escritura.html">
  Escritura
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../funciones/exploracion.html">
  Exploración
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../funciones/lectura.html">
  Lectura
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../funciones/lematizacion.html">
  Lematización
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../funciones/lenguajes.html">
  Lenguajes
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../funciones/limpieza.html">
  Limpieza
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../funciones/stemming.html">
  Stemming
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../funciones/vectorizacion.html">
  Vectorización
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../funciones/utils.html">
  Utils
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/ucd-dnp/ConTexto/" rel="noopener" target="_blank" title="GitHub ConTexto">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub ConTexto</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="mailto:ucd@dnp.gov.co" rel="noopener" target="_blank" title="Enviar correo">
            <span><i class="far fa-envelope"></i></span>
            <label class="sr-only">Enviar correo</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Buscar en la documentación ..." aria-label="Buscar en la documentación ..." autocomplete="off" >
</form>

<a id="versions_anchor" class="nav-link" data-toggle="collapse" href="#collapseExample" role="button" aria-expanded="false" aria-controls="collapseExample">
    <span class="fa fa-book"></span> Versión
        v0.1
    

    <span class="fa fa-caret-down"></span>
</a>  

<div class="collapse" id="collapseExample">
    <div class="card card-body">
            <dl>
                <dt>Versiones</dt>
                        <dd><a href="../../master/ejemplos/08_comparacion_de_textos.html">latest</a></dd>        
                    
            <!-- </dl> -->
            <!-- <dl> -->
                <!-- <dt>Tags</dt> -->

                    
                        <dd><a href="08_comparacion_de_textos.html">v0.1</a></dd>
                    
            </dl>
    </div>
</div><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01_lectura_y_escritura_de_documentos.html">
   1. Lectura y escritura de documentos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02_limpieza_de_textos.html">
   2. Limpieza de textos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_exploracion_y_visualizacion.html">
   3. Análisis exploratorio y visualización
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_correccion_ortografica.html">
   4. Corrección ortográfica
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="05_lematizacion_de_textos.html">
   5. Lematización de textos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06_stemming_de_textos.html">
   6. Stemming de textos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="07_vectorizacion_de_textos.html">
   7. Vectorización de textos
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   8. Comparación de textos
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="09_casos_de_uso.html">
   Casos de uso
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#importar-paquetes-necesarios-y-adecuar-textos-de-prueba">
   8.1. Importar paquetes necesarios y adecuar textos de prueba
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#medidas-de-similitud-entre-textos">
   8.2. Medidas de similitud entre textos
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inicializar-los-objetos-de-clase-similitud">
     8.2.1. Inicializar los objetos de clase
     <cite>
      Similitud
     </cite>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#similitud-coseno">
     8.2.2. Similitud coseno
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#similitud-de-jaccard">
     8.2.3. Similitud de Jaccard
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#similitudes-entre-dos-grupos-de-textos-distintos">
     8.2.4. Similitudes entre dos grupos de textos distintos
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#medidas-de-distancia-entre-textos">
   8.3. Medidas de distancia entre textos
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inicializar-los-objetos-de-clase-distancia">
     8.3.1. Inicializar los objetos de clase
     <cite>
      Distancia
     </cite>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#metricas-de-distancias">
     8.3.2. Métricas de distancias
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#otras-metricas-de-distancias">
     8.3.3. Otras métricas de distancias
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#distancias-entre-dos-grupos-de-textos-distintos">
     8.3.4. Distancias entre dos grupos de textos distintos
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#diferencias-entre-textos-a-nivel-de-caracteres">
   8.4. Diferencias entre textos a nivel de caracteres
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#definir-textos-de-prueba-e-inicializar-objeto-de-clase-diferenciastrings">
     8.4.1. Definir textos de prueba e inicializar objeto de clase DiferenciaStrings
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#calculo-de-medidas-de-distancia-y-similitud">
     8.4.2. Cálculo de medidas de distancia y similitud
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#normalizacion-de-medidas-de-distancia">
     8.4.3. Normalización de medidas de distancia
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#comparaciones-entre-dos-grupos-de-strings-distintos">
     8.4.4. Comparaciones entre dos grupos de strings distintos
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="comparacion-de-textos">
<span id="id1"></span><h1><span class="section-number">8. </span>Comparación de textos<a class="headerlink" href="#comparacion-de-textos" title="Enlazar permanentemente con este título">¶</a></h1>
<p>Este ejemplo muestra las principales funcionalidades del módulo <a class="reference internal" href="../funciones/comparacion.html#module-comparacion" title="comparacion"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Comparación</span></code></a>, de la librería. Este módulo permite calcular distintas métricas de distancia y similitud entre dos o mas textos. La capacidad para cuantificar qué tan similares o diferentes son un grupo de textos o cadenas de caracteres entre sí puede ser muy útil para ciertos procesos como detección de textos atípicos, identificación de afinidad entre documentos y estandarización de valores <em>string</em>, entre otros.</p>
<div class="section" id="importar-paquetes-necesarios-y-adecuar-textos-de-prueba">
<h2><span class="section-number">8.1. </span>Importar paquetes necesarios y adecuar textos de prueba<a class="headerlink" href="#importar-paquetes-necesarios-y-adecuar-textos-de-prueba" title="Enlazar permanentemente con este título">¶</a></h2>
<p>El primer paso es importar las tres clases del módulo de <cite>comparacion</cite> con las que se va a trabajar, y definir los textos para correr los ejemplos.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">contexto.comparacion</span> <span class="kn">import</span> <span class="n">Similitud</span><span class="p">,</span> <span class="n">Distancia</span><span class="p">,</span> <span class="n">DiferenciaStrings</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">contexto.vectorizacion</span> <span class="kn">import</span> <span class="o">*</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Textos para probar las medidas de similitud y distancia</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">textos_prueba</span> <span class="o">=</span> <span class="p">[</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="s1">&#39;primero de los dos textos de prueba&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="s1">&#39;segundo de los textos de evaluación&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="s1">&#39;una tercera oración que se empieza a alejar de los textos anteriores&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="s1">&#39;este no tiene ninguna relación con nada&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">otros_textos</span> <span class="o">=</span> <span class="p">[</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="s1">&#39;primer texto del segundo grupo de prueba&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="s1">&#39;segundo de la segunda lista de textos&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">]</span>
</pre></div>
</div>
<p>Adicionalmente, para el cálculo de varias distancias y similitudes es necesaria una representación numérica o vectorial de los textos. Para esto se puede trabajar directamente con los vectores que representan cada uno de los textos, o se puede utilizar alguno de los vectorizadores del módulo <a class="reference internal" href="../funciones/vectorizacion.html#module-vectorizacion" title="vectorizacion"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Vectorización</span></code></a>.</p>
<p>En este ejemplo se van a probar ambas opciones, por lo que es necesario inicializar los vectorizadores que se van a utilizar y también obtener las representaciones vectoriales de los textos de prueba.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1">## Preparar los insumos</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Definir algunos vectorizadores para hacer diferentes pruebas</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_bow</span> <span class="o">=</span> <span class="n">VectorizadorFrecuencias</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_tf</span> <span class="o">=</span> <span class="n">VectorizadorFrecuencias</span><span class="p">(</span><span class="n">tipo</span><span class="o">=</span><span class="s1">&#39;tfidf&#39;</span><span class="p">,</span> <span class="n">idf</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_tfidf</span> <span class="o">=</span> <span class="n">VectorizadorFrecuencias</span><span class="p">(</span><span class="n">tipo</span><span class="o">=</span><span class="s1">&#39;tfidf&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_hashing</span> <span class="o">=</span> <span class="n">VectorizadorHash</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_word2vec</span> <span class="o">=</span> <span class="n">VectorizadorWord2Vec</span><span class="p">()</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Ajustar los vectorizadores (cuando aplique) al corpus de textos</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_bow</span><span class="o">.</span><span class="n">ajustar</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_tf</span><span class="o">.</span><span class="n">ajustar</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_tfidf</span><span class="o">.</span><span class="n">ajustar</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Obtener representaciones vectoriales de los textos y guardarlas en un diccionario</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vectores</span> <span class="o">=</span> <span class="p">{}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">llaves</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;bow&#39;</span><span class="p">,</span> <span class="s1">&#39;tf&#39;</span><span class="p">,</span> <span class="s1">&#39;tfidf&#39;</span><span class="p">,</span> <span class="s1">&#39;hash&#39;</span><span class="p">,</span> <span class="s1">&#39;word2vec&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="n">v_bow</span><span class="p">,</span> <span class="n">v_tf</span><span class="p">,</span> <span class="n">v_tfidf</span><span class="p">,</span> <span class="n">v_hashing</span><span class="p">,</span> <span class="n">v_word2vec</span><span class="p">]):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">vectores</span><span class="p">[</span><span class="n">llaves</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">vectorizar</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="medidas-de-similitud-entre-textos">
<h2><span class="section-number">8.2. </span>Medidas de similitud entre textos<a class="headerlink" href="#medidas-de-similitud-entre-textos" title="Enlazar permanentemente con este título">¶</a></h2>
<p>La clase <a class="reference internal" href="../funciones/comparacion.html#comparacion.Similitud" title="comparacion.Similitud"><code class="xref py py-class docutils literal notranslate"><span class="pre">Similitud</span></code></a> permite calcular dos métricas de similitud, coseno y Jaccard, para cuantificar qué tan parecidos son dos textos entre sí. Entre más alto sea el valor de similitud (valor máximo es 1), más similares serán los dos textos.</p>
<div class="section" id="inicializar-los-objetos-de-clase-similitud">
<h3><span class="section-number">8.2.1. </span>Inicializar los objetos de clase <cite>Similitud</cite><a class="headerlink" href="#inicializar-los-objetos-de-clase-similitud" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Al inicializar los objetos de clase <a class="reference internal" href="../funciones/comparacion.html#comparacion.Similitud" title="comparacion.Similitud"><code class="xref py py-class docutils literal notranslate"><span class="pre">Similitud</span></code></a> se pasa como parámetro un vectorizador para poder obtener las representaciones vectoriales de los textos de entrada que se le pasen. Si no se pasa ningún vectorizador, por defecto inicializará uno de la clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorWord2Vec" title="vectorizacion.VectorizadorWord2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorWord2Vec</span></code></a>, del idioma especificado por el usuario (por defecto: español). Si a los métodos del objeto de clase <a class="reference internal" href="../funciones/comparacion.html#comparacion.Similitud" title="comparacion.Similitud"><code class="xref py py-class docutils literal notranslate"><span class="pre">Similitud</span></code></a> se pasan vectores en vez de textos como entrada, no importa qué vectorizador tenga, pues no lo utilizará.</p>
<p>Es importante recalcar que si se pasa un vectorizador al objeto de Similitud, este ya debe estar ajustado, en caso de que aplique. Esto es particularmente relevante para los vectores de clases <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorFrecuencias" title="vectorizacion.VectorizadorFrecuencias"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorFrecuencias</span></code></a> y <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorDoc2Vec" title="vectorizacion.VectorizadorDoc2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorDoc2Vec</span></code></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1">## Inicializar objetos de clase Similitud</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s_bow</span> <span class="o">=</span> <span class="n">Similitud</span><span class="p">(</span><span class="n">v_bow</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s_tf</span> <span class="o">=</span> <span class="n">Similitud</span><span class="p">(</span><span class="n">v_tf</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s_tfidf</span> <span class="o">=</span> <span class="n">Similitud</span><span class="p">(</span><span class="n">v_tfidf</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s_hashing</span> <span class="o">=</span> <span class="n">Similitud</span><span class="p">(</span><span class="n">v_hashing</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s_word2vec</span> <span class="o">=</span> <span class="n">Similitud</span><span class="p">(</span><span class="n">v_word2vec</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="similitud-coseno">
<h3><span class="section-number">8.2.2. </span>Similitud coseno<a class="headerlink" href="#similitud-coseno" title="Enlazar permanentemente con este título">¶</a></h3>
<p>La similitud coseno es un valor entre -1 y 1 que mide qué tan «alineados» están dos vectores. Este valor se puede obtener al llamar el método <a class="reference internal" href="../funciones/comparacion.html#comparacion.Similitud.coseno" title="comparacion.Similitud.coseno"><code class="xref py py-meth docutils literal notranslate"><span class="pre">coseno()</span></code></a> del objeto de clase <a class="reference internal" href="../funciones/comparacion.html#comparacion.Similitud" title="comparacion.Similitud"><code class="xref py py-class docutils literal notranslate"><span class="pre">Similitud</span></code></a>. Como argumentos se pueden pasar:</p>
<ul class="simple">
<li><p>Dos textos (o vectores). En este caso se retornará un arreglo de numpy de dos dimensiones, con el valor de la similitud entre las dos entradas.</p></li>
<li><p>Una lista de <em>n</em> textos (o vectores). En este caso se retornará un arreglo de numpy de dos dimensiones, que representa una matriz de <em>nxn</em> simétrica, en donde la posición <em>i,j</em> muestra la similitud del texto/vector <em>i</em> con el texto/vector <em>j</em>.</p></li>
<li><p>Dos listas de <em>n1</em> y <em>n2</em> textos (o vectores), respectivamente. En este caso se retornará un arreglo de numpy de dos dimensiones, que representa una matriz de <em>n1xn2</em>, en donde la posición <em>i,j</em> muestra la similitud del texto/vector <em>i</em> de la primera lista con el texto/vector <em>j</em> de la segunda lista.</p></li>
</ul>
<p>Los vectorizadores basados en frecuencias (sin consideraciones adicionales, como tener en cuenta la frecuencia inversa IDF) arrojarán resultados muy similares al medir la similitud coseno, incluso si los valores de los vectores generados no son los mismos.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1">## Calcular similitudes con vectorizadores basados en frecuencias de términos</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">coseno_bow</span> <span class="o">=</span> <span class="n">s_bow</span><span class="o">.</span><span class="n">coseno</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">coseno_tf</span> <span class="o">=</span> <span class="n">s_tf</span><span class="o">.</span><span class="n">coseno</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">coseno_hashing</span> <span class="o">=</span> <span class="n">s_hashing</span><span class="o">.</span><span class="n">coseno</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># La vectorización TF-IDF tiene unos resultados distintos</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">coseno_tfidf</span> <span class="o">=</span> <span class="n">s_tfidf</span><span class="o">.</span><span class="n">coseno</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Similitudes entre los textos de prueba (BOW, TF o HASHING):&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">coseno_bow</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;----------</span><span class="se">\n</span><span class="s1">Similitudes entre los textos de prueba (TF-IDF):&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">coseno_tfidf</span><span class="p">,</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="go">Similitudes entre los textos de prueba (BOW, TF o HASHING):</span>
<span class="go">[[1.         0.70710678 0.40201513 0.        ]</span>
<span class="go"> [0.70710678 1.         0.42640143 0.        ]</span>
<span class="go"> [0.40201513 0.42640143 1.         0.        ]</span>
<span class="go"> [0.         0.         0.         1.        ]]</span>
<span class="go">----------</span>
<span class="go">Similitudes entre los textos de prueba (TF-IDF):</span>
<span class="go">[[1.         0.49693115 0.22998344 0.        ]</span>
<span class="go"> [0.49693115 1.         0.25454493 0.        ]</span>
<span class="go"> [0.22998344 0.25454493 1.         0.        ]</span>
<span class="go"> [0.         0.         0.         1.        ]]</span>
</pre></div>
</div>
<p>En general, los vectorizadores basados en frecuencias tendrán diferencias mayores dependiendo de las palabras que estén presentes en los textos. Los vectorizadores densos como word2vec o doc2vec son menos radicales, lo que permite encontrar similitud entre textos con significados parecidos, incluso si no tienen tantas palabras en común.</p>
<p>También es posible ingresar directamente los vectores pre-calculados. Esto debería arrojar los mismos resultados que ingresando los textos, siempre y cuando se haya utilizado el mismo vectorizador.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">coseno_doc2vec</span> <span class="o">=</span> <span class="n">s_word2vec</span><span class="o">.</span><span class="n">coseno</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Similitudes entre los textos de prueba (Word2Vec):&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">coseno_doc2vec</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">coseno_tfidf_vec</span> <span class="o">=</span> <span class="n">s_tfidf</span><span class="o">.</span><span class="n">coseno</span><span class="p">(</span><span class="n">vectores</span><span class="p">[</span><span class="s1">&#39;tfidf&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iguales</span> <span class="o">=</span> <span class="p">(</span><span class="n">coseno_tfidf</span> <span class="o">==</span> <span class="n">coseno_tfidf_vec</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-----------&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Igualdad entre utilizar los textos directamente o sus representaciones vectoriales:&#39;</span><span class="p">,</span> <span class="n">iguales</span><span class="p">,</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="go">Similitudes entre los textos de prueba (Word2Vec):</span>
<span class="go">[[1.0000001  0.9347326  0.6558729  0.23863341]</span>
<span class="go"> [0.9347326  0.9999998  0.64198124 0.22747502]</span>
<span class="go"> [0.6558729  0.64198124 0.9999997  0.49457312]</span>
<span class="go"> [0.23863341 0.22747502 0.49457312 1.0000004 ]]</span>
<span class="go">-----------</span>
<span class="go">Igualdad entre utilizar los textos directamente o sus representaciones vectoriales: False</span>
</pre></div>
</div>
<p>En este caso la validación dio que las representaciones vectoriales no son exactamente iguales. Esto se debe al grado de precisión que tiene Python para manejar números muy pequeños, el cual tiene cierto margen de error.</p>
<p>Sin embargo, si se mira la diferencia entre ambos objetos, se puede ver que son prácticamente la mísma representación numérica.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Diferencia entre utilizar los textos directamente o sus representaciones vectoriales:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">coseno_tfidf</span> <span class="o">-</span> <span class="n">coseno_tfidf_vec</span><span class="p">)</span>

<span class="go">Diferencia entre utilizar los textos directamente o sus representaciones vectoriales:</span>

<span class="go">[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]</span>
<span class="go"> [0.00000000e+00 2.22044605e-16 0.00000000e+00 0.00000000e+00]</span>
<span class="go"> [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]</span>
<span class="go"> [0.00000000e+00 0.00000000e+00 0.00000000e+00 2.22044605e-16]]</span>
</pre></div>
</div>
</div>
<div class="section" id="similitud-de-jaccard">
<h3><span class="section-number">8.2.3. </span>Similitud de Jaccard<a class="headerlink" href="#similitud-de-jaccard" title="Enlazar permanentemente con este título">¶</a></h3>
<p>La similitud de Jaccard es un valor entre 0 y 1 que mide cuántos elementos tienen en común dos vectores, al calcular la intersección sobre la unión de los elementos. Este valor se puede obtener al llamar el método <a class="reference internal" href="../funciones/comparacion.html#comparacion.Similitud.jaccard" title="comparacion.Similitud.jaccard"><code class="xref py py-meth docutils literal notranslate"><span class="pre">jaccard()</span></code></a> del objeto de clase <a class="reference internal" href="../funciones/comparacion.html#comparacion.Similitud" title="comparacion.Similitud"><code class="xref py py-class docutils literal notranslate"><span class="pre">Similitud</span></code></a>. Las entradas y salidas de este método son iguales a las del método <a class="reference internal" href="../funciones/comparacion.html#comparacion.Similitud.coseno" title="comparacion.Similitud.coseno"><code class="xref py py-meth docutils literal notranslate"><span class="pre">coseno()</span></code></a>.</p>
<p>El cálculo de la similitud de Jaccard funciona bien con vectorizadores basados en frecuencias (BOW, TF-IDF, Hashing), o directamente con los textos sin vectorizar, aunque en este segundo caso pueden presentarse resultados distintos. Esto se debe a que, sí se pasan directamente los textos sin vectorizar, la «unión» de elementos se definirá como todos los términos que aparecen en por lo menos uno de los dos textos. Por otro lado, si se usa, por ejemplo, un vectorizador BOW con un vocabulario más amplio para hacer la vectorización, es posible que hayan palabras en dicho vocabulario que cuentan en la unión de elementos, pero realmente no están en ninguno de los dos textos a comparar.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Utilizar el parámetro &quot;vectorizar=True&quot; debería dar el mismo resultado</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># que aplicar la función directamente sobre vectores pre computados</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">s_bow</span><span class="o">.</span><span class="n">jaccard</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">,</span> <span class="n">vectorizar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">s_bow</span><span class="o">.</span><span class="n">jaccard</span><span class="p">(</span><span class="n">vectores</span><span class="p">[</span><span class="s1">&#39;bow&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">((</span><span class="n">a</span> <span class="o">==</span> <span class="n">b</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">())</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Al aplicar la función directamente sobre los textos, los resultados pueden</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># variar, dado que solo se toma en cuenta el vocabulario de cada par de textos</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># a comparar (a diferencia del vocabulario total del corpus que se tiene en</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># cuenta en el vectorizador)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">s_bow</span><span class="o">.</span><span class="n">jaccard</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">==</span> <span class="n">c</span>

<span class="go">True</span>
<span class="go">array([[ True,  True, False,  True],</span>
<span class="go">       [ True,  True, False,  True],</span>
<span class="go">       [False, False,  True,  True],</span>
<span class="go">       [ True,  True,  True,  True]])</span>
</pre></div>
</div>
<p>Mientras los vectorizadores utilizados sean basados en frecuencias, el cálculo de similitud Jaccard funcionará bien. Por el otro lado, los vectorizadores word2vec y doc2vec generan una representación densa, por lo que no dan buenos resultados al utilizarse en este caso.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Cálculo utilizando vectorizadores basados en frecuencias</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jaccard_tfidf</span> <span class="o">=</span> <span class="n">s_tfidf</span><span class="o">.</span><span class="n">jaccard</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">,</span> <span class="n">vectorizar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jaccard_hashing</span> <span class="o">=</span> <span class="n">s_hashing</span><span class="o">.</span><span class="n">jaccard</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">,</span> <span class="n">vectorizar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Similitudes entre los textos de prueba (TF-IDF o HASHING):&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">jaccard_tfidf</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Cálculo utilizando word2vec</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jaccard_word2vec</span> <span class="o">=</span> <span class="n">s_word2vec</span><span class="o">.</span><span class="n">jaccard</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">,</span> <span class="n">vectorizar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-------</span><span class="se">\n</span><span class="s1">Similitudes entre los textos de prueba (Word2Vec):&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">jaccard_word2vec</span><span class="p">)</span>

<span class="go">Similitudes entre los textos de prueba (TF-IDF o HASHING):</span>
<span class="go">[[1.         0.375      0.21428571 0.        ]</span>
<span class="go"> [0.375      1.         0.23076923 0.        ]</span>
<span class="go"> [0.21428571 0.23076923 1.         0.        ]</span>
<span class="go"> [0.         0.         0.         1.        ]]</span>
<span class="go">-------</span>
<span class="go">Similitudes entre los textos de prueba (Word2Vec):</span>
<span class="go">[[1. 1. 1. 1.]</span>
<span class="go"> [1. 1. 1. 1.]</span>
<span class="go"> [1. 1. 1. 1.]</span>
<span class="go"> [1. 1. 1. 1.]]</span>
</pre></div>
</div>
</div>
<div class="section" id="similitudes-entre-dos-grupos-de-textos-distintos">
<h3><span class="section-number">8.2.4. </span>Similitudes entre dos grupos de textos distintos<a class="headerlink" href="#similitudes-entre-dos-grupos-de-textos-distintos" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Como se mencionó anteriormente, es posible medir la similitud entre dos grupos de textos distintos. Para esto, se deben introducir como argumentos dos listas de textos o vectores distintas. Los métodos de la clase <a class="reference internal" href="../funciones/comparacion.html#comparacion.Similitud" title="comparacion.Similitud"><code class="xref py py-class docutils literal notranslate"><span class="pre">Similitud</span></code></a> calcularán la similitud indicada entre cada uno de los elementos de la primera lista y cada uno de los elementos de la segunda lista.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">jaccard_bow</span> <span class="o">=</span> <span class="n">s_bow</span><span class="o">.</span><span class="n">jaccard</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">,</span> <span class="n">otros_textos</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">coseno_word2vec</span> <span class="o">=</span> <span class="n">s_word2vec</span><span class="o">.</span><span class="n">coseno</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">,</span> <span class="n">otros_textos</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Similitudes de Jaccard entre dos grupos de textos (BOW):&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">jaccard_bow</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-------</span><span class="se">\n</span><span class="s1">Similitudes coseno entre los textos de prueba y otro texto (Word2Vec):&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">coseno_word2vec</span><span class="p">)</span>

<span class="go">Similitudes de Jaccard entre dos grupos de textos (BOW):</span>
<span class="go">[[0.18181818 0.2       ]</span>
<span class="go"> [0.2        0.375     ]</span>
<span class="go"> [0.05555556 0.125     ]</span>
<span class="go"> [0.         0.        ]]</span>
<span class="go">-------</span>
<span class="go">Similitudes coseno entre los textos de prueba y otro texto (Word2Vec):</span>
<span class="go">[[0.70599896]</span>
<span class="go"> [0.77385116]</span>
<span class="go"> [0.4849984 ]</span>
<span class="go"> [0.24222623]]</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="medidas-de-distancia-entre-textos">
<h2><span class="section-number">8.3. </span>Medidas de distancia entre textos<a class="headerlink" href="#medidas-de-distancia-entre-textos" title="Enlazar permanentemente con este título">¶</a></h2>
<p>La clase <code class="xref py py-class docutils literal notranslate"><span class="pre">Distancia</span></code> permite calcular varias métricas de distancia para cuantificar qué tan diferentes son dos textos entre sí. Entre más bajo sea el valor de distancia (valor mínimo es 0), más similares serán los dos textos.</p>
<div class="section" id="inicializar-los-objetos-de-clase-distancia">
<h3><span class="section-number">8.3.1. </span>Inicializar los objetos de clase <cite>Distancia</cite><a class="headerlink" href="#inicializar-los-objetos-de-clase-distancia" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Al inicializar los objetos de clase <code class="xref py py-class docutils literal notranslate"><span class="pre">Distancia</span></code> se pasa como parámetro un vectorizador para poder obtener las representaciones vectoriales de los textos de entrada que se le pasen. Si no se pasa ningún vectorizador, por defecto inicializará uno de la clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorWord2Vec" title="vectorizacion.VectorizadorWord2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorWord2Vec</span></code></a>, del idioma especificado por el usuario (por defecto: español). Si a los métodos del objeto de clase <code class="xref py py-class docutils literal notranslate"><span class="pre">Distancia</span></code> se pasan vectores en vez de textos como entrada, no importa qué vectorizador tenga, pues no lo utilizará.</p>
<p>Es importante recalcar que si se pasa un vectorizador al objeto de Similitud, este ya debe estar ajustado, en caso de que aplique. Esto es particularmente relevante para los vectores de clases <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorFrecuencias" title="vectorizacion.VectorizadorFrecuencias"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorFrecuencias</span></code></a> y <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorDoc2Vec" title="vectorizacion.VectorizadorDoc2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorDoc2Vec</span></code></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1">## Inicializar objetos de clase Distancia</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d_bow</span> <span class="o">=</span> <span class="n">Distancia</span><span class="p">(</span><span class="n">v_bow</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d_tf</span> <span class="o">=</span> <span class="n">Distancia</span><span class="p">(</span><span class="n">v_tf</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d_tfidf</span> <span class="o">=</span> <span class="n">Distancia</span><span class="p">(</span><span class="n">v_tfidf</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d_hashing</span> <span class="o">=</span> <span class="n">Distancia</span><span class="p">(</span><span class="n">v_hashing</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d_word2vec</span> <span class="o">=</span> <span class="n">Distancia</span><span class="p">(</span><span class="n">v_word2vec</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="metricas-de-distancias">
<h3><span class="section-number">8.3.2. </span>Métricas de distancias<a class="headerlink" href="#metricas-de-distancias" title="Enlazar permanentemente con este título">¶</a></h3>
<p>La clase <code class="xref py py-class docutils literal notranslate"><span class="pre">Distancia</span></code> permite calcular más de 5 métricas de distancia distintas, que se muestran en las siguientes celdas de este cuaderno. En general, los argumentos de entrada y las salidas funcionan igual al caso de las similitudes. Se tienen los siguientes casos:</p>
<ul class="simple">
<li><p>Dos textos (o vectores). En este caso se retornará un arreglo de numpy de dos dimensiones, con el valor de la distancia entre las dos entradas.</p></li>
<li><p>Una lista de <em>n</em> textos (o vectores). En este caso se retornará un arreglo de numpy de dos dimensiones, que representa una matriz de <em>nxn</em> simétrica, en donde la posición <em>i,j</em> muestra la distancia del texto/vector <em>i</em> con el texto/vector <em>j</em>.</p></li>
<li><p>Dos listas de <em>n1</em> y <em>n2</em> textos (o vectores), respectivamente. En este caso se retornará un arreglo de numpy de dos dimensiones, que representa una matriz de <em>n1xn2</em>, en donde la posición <em>i,j</em> muestra la distancia del texto/vector <em>i</em> de la primera lista con el texto/vector <em>j</em> de la segunda lista.</p></li>
</ul>
<p>En este caso, los valores de distancias generalmente variarán dependiendo del vectorizador utilizado (a diferencia de las similitudes, que en algunos casos calculaban los mismos valores para vectorizadores distintos). En todo caso, a pesar de que cambien los valores y las escalas, en general sí se debería mantener un mismo orden. Es decir, textos más cercanos y más lejanos entre sí deberían mantener este comportameniento sin importar el vectorizador utilizado.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1">## Métricas de distancia definidas</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Distancia L1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l1_bow</span> <span class="o">=</span> <span class="n">d_bow</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Distancia L2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l2_word2vec</span> <span class="o">=</span><span class="n">d_word2vec</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Distancia Hamming</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hamming_hashing</span> <span class="o">=</span> <span class="n">d_hashing</span><span class="o">.</span><span class="n">hamming</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Distancias L2 entre los textos de prueba (Word2Vec):&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">l2_word2vec</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-----</span><span class="se">\n</span><span class="s1">Distancias de Hamming entre los textos de prueba (HASHING):&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">hamming_hashing</span><span class="p">)</span>

<span class="go">Distancias L2 entre los textos de prueba (Word2Vec):</span>
<span class="go">[[ 0.       10.218398 20.964655 31.797607]</span>
<span class="go"> [10.218398  0.       22.503887 33.3239  ]</span>
<span class="go"> [20.964655 22.503887  0.       23.959114]</span>
<span class="go"> [31.797607 33.3239   23.959114  0.      ]]</span>
<span class="go">-----</span>
<span class="go">Distancias de Hamming entre los textos de prueba (HASHING):</span>
<span class="go">[[0.   0.08 0.14 0.13]</span>
<span class="go"> [0.08 0.   0.13 0.12]</span>
<span class="go"> [0.14 0.13 0.   0.18]</span>
<span class="go"> [0.13 0.12 0.18 0.  ]]</span>
</pre></div>
</div>
<p>La distancia Minkowski es una generalización de las operaciones que se utilizan para calcular la distancia L1 o L2. El parámetro p permite definir el grado a utilizar en el cálculo de la distancia.</p>
<p>Por ejemplo, si p=1, se calculará la distancia L1 y si p=2 se calculará la distancia L2.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1">## Distancia Minkowski</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Distancia con grado 3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l3_tfidf</span> <span class="o">=</span><span class="n">d_tfidf</span><span class="o">.</span><span class="n">minkowski</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Misma distancia L2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">minkowski_2_word2vec</span> <span class="o">=</span> <span class="n">d_word2vec</span><span class="o">.</span><span class="n">minkowski</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iguales</span> <span class="o">=</span> <span class="p">(</span><span class="n">l2_word2vec</span> <span class="o">==</span> <span class="n">minkowski_2_word2vec</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Distancias de Minkowski (grado 3) entre los textos de prueba (TF-IDF):&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">l3_tfidf</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-----</span><span class="se">\n</span><span class="s1">Distancias de Minkowski grado 2 iguales a distancias L2 (Word2Vec):&#39;</span><span class="p">,</span> <span class="n">iguales</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="go">Distancias de Minkowski (grado 3) entre los textos de prueba (TF-IDF):</span>
<span class="go">[[0.         0.76622556 0.82452962 0.93553864]</span>
<span class="go"> [0.76622556 0.         0.82547379 0.95425713]</span>
<span class="go"> [0.82452962 0.82547379 0.         0.88428327]</span>
<span class="go"> [0.93553864 0.95425713 0.88428327 0.        ]]</span>
<span class="go">-----</span>
<span class="go">Distancias de Minkowski grado 2 iguales a distancias L2 (Word2Vec): True</span>
</pre></div>
</div>
<p>Una de las distancias que se pueden calcular es la distancia de Jaccard. Esta distancia es complementaria a la similitud de Jaccard, por lo que la suma de ambas medidas siempre debe ser igual a 1.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Distancia Jaccard</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jaccard_tfidf</span> <span class="o">=</span> <span class="n">d_tfidf</span><span class="o">.</span><span class="n">jaccard</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># La suma de la distancia y similitud de jaccard entre dos vectores debería dar 1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jaccard_tfidf</span> <span class="o">+</span> <span class="n">s_tfidf</span><span class="o">.</span><span class="n">jaccard</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">,</span> <span class="n">vectorizar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="go">array([[1., 1., 1., 1.],</span>
<span class="go">       [1., 1., 1., 1.],</span>
<span class="go">       [1., 1., 1., 1.],</span>
<span class="go">       [1., 1., 1., 1.]])</span>
</pre></div>
</div>
</div>
<div class="section" id="otras-metricas-de-distancias">
<h3><span class="section-number">8.3.3. </span>Otras métricas de distancias<a class="headerlink" href="#otras-metricas-de-distancias" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Adicionalmente a las funciones que la clase <code class="xref py py-class docutils literal notranslate"><span class="pre">Distancia</span></code> trae implementadas, el método <a class="reference internal" href="../funciones/comparacion.html#comparacion.Distancia.distancia_pares" title="comparacion.Distancia.distancia_pares"><code class="xref py py-meth docutils literal notranslate"><span class="pre">distancia_pares()</span></code></a> permite calcular otras distancias, que se especifican por medio del parámetro <em>tipo_distancia</em>. Las métricas que se pueden utilizar son las soportadas por scikit-learn y scipy. Para mayor información, se puede consultar la
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html">documentación de scikit-learn</a> .</p>
<p>Algunas de estas métricas pueden requerir o aceptar argumentos adicionales. Estos parámetros pueden ser pasados al método <a class="reference internal" href="../funciones/comparacion.html#comparacion.Distancia.distancia_pares" title="comparacion.Distancia.distancia_pares"><code class="xref py py-meth docutils literal notranslate"><span class="pre">distancia_pares()</span></code></a> con el mismo nombre con el que aparezcan en la documentación de scikit-learn y <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/spatial.distance.html">la documentación de scipy</a> .</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Algunos ejemplos:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">chebyshev_word2vec</span> <span class="o">=</span> <span class="n">d_word2vec</span><span class="o">.</span><span class="n">distancia_pares</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">,</span> <span class="n">tipo_distancia</span><span class="o">=</span><span class="s1">&#39;chebyshev&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rogerstanimoto_bow</span> <span class="o">=</span> <span class="n">d_bow</span><span class="o">.</span><span class="n">distancia_pares</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">,</span> <span class="n">tipo_distancia</span><span class="o">=</span><span class="s1">&#39;rogerstanimoto&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">braycurtis_tfidf</span> <span class="o">=</span> <span class="n">d_tfidf</span><span class="o">.</span><span class="n">distancia_pares</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">,</span> <span class="n">tipo_distancia</span><span class="o">=</span><span class="s1">&#39;braycurtis&#39;</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1"> ::: Distancia chebyshev&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">chebyshev_word2vec</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">::: Distancia rogerstanimoto&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">rogerstanimoto_bow</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">::: Distancia braycurtis&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">braycurtis_tfidf</span><span class="p">)</span>

<span class="go"> ::: Distancia chebyshev</span>
<span class="go">[[0.         1.83772638 3.40704679 6.52587652]</span>
<span class="go"> [1.83772638 0.         3.68807423 6.6068573 ]</span>
<span class="go"> [3.40704679 3.68807423 0.         4.78639138]</span>
<span class="go"> [6.52587652 6.6068573  4.78639138 0.        ]]</span>

<span class="go">::: Distancia rogerstanimoto</span>
<span class="go">[[0.         0.35714286 0.64705882 0.72222222]</span>
<span class="go"> [0.35714286 0.         0.60606061 0.68571429]</span>
<span class="go"> [0.64705882 0.60606061 0.         0.87804878]</span>
<span class="go"> [0.72222222 0.68571429 0.87804878 0.        ]]</span>

<span class="go">::: Distancia braycurtis</span>
<span class="go">[[0.         0.51793548 0.77659126 1.        ]</span>
<span class="go"> [0.51793548 0.         0.76752362 1.        ]</span>
<span class="go"> [0.77659126 0.76752362 0.         1.        ]</span>
<span class="go"> [1.         1.         1.         0.        ]]</span>
</pre></div>
</div>
</div>
<div class="section" id="distancias-entre-dos-grupos-de-textos-distintos">
<h3><span class="section-number">8.3.4. </span>Distancias entre dos grupos de textos distintos<a class="headerlink" href="#distancias-entre-dos-grupos-de-textos-distintos" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Como se mencionó anteriormente, es posible medir la distancia entre dos grupos de textos distintos. Para esto, se deben introducir como argumentos dos listas de textos o vectores distintas. Los métodos de la clase <code class="xref py py-class docutils literal notranslate"><span class="pre">Distancia</span></code> calcularán la distancia indicada entre cada uno de los elementos de la primera lista y cada uno de los elementos de la segunda lista.</p>
<p>Esto aplica para cualquiera de los métodos de la clase <code class="xref py py-class docutils literal notranslate"><span class="pre">Distancia</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">l1_hash</span> <span class="o">=</span> <span class="n">d_hashing</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">,</span> <span class="n">otros_textos</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">braycurtis_tfidf</span> <span class="o">=</span> <span class="n">d_tfidf</span><span class="o">.</span><span class="n">distancia_pares</span><span class="p">(</span><span class="n">vectores</span><span class="p">[</span><span class="s1">&#39;tfidf&#39;</span><span class="p">],</span> <span class="n">otros_textos</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tipo_distancia</span><span class="o">=</span><span class="s1">&#39;braycurtis&#39;</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Distancias L1 entre dos grupos de textos (HASHING):&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">l1_hash</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-------</span><span class="se">\n</span><span class="s1">Distancias (disimilitud) de Bray–Curtis entre los textos de prueba y otro texto (TF-IDF):&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">braycurtis_tfidf</span><span class="p">)</span>

<span class="go">Distancias L1 entre dos grupos de textos (HASHING):</span>
<span class="go">[[3.55648903 2.66666667]</span>
<span class="go"> [3.30403593 1.78798701]</span>
<span class="go"> [5.35935341 4.44391275]</span>
<span class="go"> [5.29150262 4.97908464]]</span>
<span class="go">-------</span>
<span class="go">Distancias (disimilitud) de Bray–Curtis entre los textos de prueba y otro texto (TF-IDF):</span>
<span class="go">[[0.58829081]</span>
<span class="go"> [0.54109359]</span>
<span class="go"> [0.91533873]</span>
<span class="go"> [1.        ]]</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="diferencias-entre-textos-a-nivel-de-caracteres">
<h2><span class="section-number">8.4. </span>Diferencias entre textos a nivel de caracteres<a class="headerlink" href="#diferencias-entre-textos-a-nivel-de-caracteres" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Finalmente, la clase <a class="reference internal" href="../funciones/comparacion.html#comparacion.DiferenciaStrings" title="comparacion.DiferenciaStrings"><code class="xref py py-class docutils literal notranslate"><span class="pre">DiferenciaStrings</span></code></a> permite calcular métricas, tanto de similitud como de distancia, para cuantificar a nivel de caracteres qué tan parecidos o diferentes son dos textos entre sí. Esta clase se recomienda para comparaciones de cadenas de caracteres (strings) relativamente cortas, como nombres, direcciones y otras cadenas de caracteres similares. Para textos más largos, se recomiendan las clases <code class="xref py py-class docutils literal notranslate"><span class="pre">Similitud</span></code> y/o <code class="xref py py-class docutils literal notranslate"><span class="pre">Distancia</span></code>.</p>
<div class="section" id="definir-textos-de-prueba-e-inicializar-objeto-de-clase-diferenciastrings">
<h3><span class="section-number">8.4.1. </span>Definir textos de prueba e inicializar objeto de clase DiferenciaStrings<a class="headerlink" href="#definir-textos-de-prueba-e-inicializar-objeto-de-clase-diferenciastrings" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Como se mencionó anteriormente, esta clase funciona mejor con textos cortos, por lo que se definen 4 strings más cortos para correr el ejemplo. También se define un objeto de clase <a class="reference internal" href="../funciones/comparacion.html#comparacion.DiferenciaStrings" title="comparacion.DiferenciaStrings"><code class="xref py py-class docutils literal notranslate"><span class="pre">DiferenciaStrings</span></code></a>, que contiene todos los métodos necesarios para calcular las similitudes y distancias.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1">## Textos de prueba</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t1</span> <span class="o">=</span> <span class="s1">&#39;pescado&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t2</span> <span class="o">=</span> <span class="s1">&#39;pecsado&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t3</span> <span class="o">=</span> <span class="s1">&#39;Jonhatan Ruiz Diaz&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t4</span> <span class="o">=</span> <span class="s1">&#39;Jonatan Ruis Díaz&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">strings</span> <span class="o">=</span> <span class="p">[</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">,</span> <span class="n">t3</span><span class="p">,</span> <span class="n">t4</span><span class="p">]</span>
<span class="go">​</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">## Inicializar objeto de clase Distancia</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dif_strings</span> <span class="o">=</span> <span class="n">DiferenciaStrings</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="calculo-de-medidas-de-distancia-y-similitud">
<h3><span class="section-number">8.4.2. </span>Cálculo de medidas de distancia y similitud<a class="headerlink" href="#calculo-de-medidas-de-distancia-y-similitud" title="Enlazar permanentemente con este título">¶</a></h3>
<p>La clase <a class="reference internal" href="../funciones/comparacion.html#comparacion.DiferenciaStrings" title="comparacion.DiferenciaStrings"><code class="xref py py-class docutils literal notranslate"><span class="pre">DiferenciaStrings</span></code></a> utiliza por debajo la librería jellyfish para calcular las diferencias y similitudes a niveles de caracteres. Para mayor información sobre las medidas disponibles y en qué consiste cada una, se puede consultar la
<a class="reference external" href="https://jellyfish.readthedocs.io/en/latest/comparison.html">documentación de jellyfish</a>.</p>
<p>Para todos los métodos de esta clase, las entradas y salidas funcionan muy similar a los vistos anteriormente para <cite>Similitud</cite> y <cite>Distancia</cite>:</p>
<ul class="simple">
<li><p>Dos textos. En este caso se retornará un arreglo de numpy de dos dimensiones, con el valor de la comparación entre las dos entradas.</p></li>
<li><p>Una lista de <em>n</em> textos. En este caso se retornará un arreglo de numpy de dos dimensiones, que representa una matriz de <em>nxn</em> simétrica, en donde la posición <em>i,j</em> muestra la comparación del texto/vector <em>i</em> con el texto/vector <em>j</em>.</p></li>
<li><p>Dos listas de <em>n1</em> y <em>n2</em> textos, respectivamente. En este caso se retornará un arreglo de numpy de dos dimensiones, que representa una matriz de <em>n1xn2</em>, en donde la posición <em>i,j</em> muestra la comparación del texto <em>i</em> de la primera lista con el texto <em>j</em> de la segunda lista.</p></li>
</ul>
<p>La gran diferencia en este caso es que la clase <a class="reference internal" href="../funciones/comparacion.html#comparacion.DiferenciaStrings" title="comparacion.DiferenciaStrings"><code class="xref py py-class docutils literal notranslate"><span class="pre">DiferenciaStrings</span></code></a> no utiliza representaciones vectoriales de los textos, por lo que siempre deben ingresarse los textos a comparar en forma de <em>strings</em>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1">## Diferencia entre dos textos</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d1</span> <span class="o">=</span> <span class="n">dif_strings</span><span class="o">.</span><span class="n">distancia_levenshtein</span><span class="p">(</span><span class="n">t3</span><span class="p">,</span><span class="n">t4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d2</span> <span class="o">=</span> <span class="n">dif_strings</span><span class="o">.</span><span class="n">distancia_damerau_levenshtein</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span><span class="n">t2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d3</span> <span class="o">=</span> <span class="n">dif_strings</span><span class="o">.</span><span class="n">distancia_hamming</span><span class="p">(</span><span class="n">strings</span><span class="p">)</span>
<span class="go">​&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Distancia de Levenshtein entre 2 textos de prueba:&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">d1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;------</span><span class="se">\n</span><span class="s1">Distancias de Hamming entre los textos de prueba:&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">d3</span><span class="p">)</span>

<span class="go">Distancia de Levenshtein entre 2 textos de prueba:</span>
<span class="go">[[3.]]</span>
<span class="go">------</span>
<span class="go">Distancias de Hamming entre los textos de prueba:</span>
<span class="go">[[ 0.  2. 17. 17.]</span>
<span class="go"> [ 2.  0. 17. 17.]</span>
<span class="go"> [17. 17.  0. 15.]</span>
<span class="go"> [17. 17. 15.  0.]]</span>
<span class="go"> ​</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1">## Similitud entre strings</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Similitud entre dos textos</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s1</span> <span class="o">=</span> <span class="n">dif_strings</span><span class="o">.</span><span class="n">similitud_jaro</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span><span class="n">t2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Similitud entre lista de textos</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s2</span> <span class="o">=</span> <span class="n">dif_strings</span><span class="o">.</span><span class="n">similitud_jaro_winkler</span><span class="p">(</span><span class="n">strings</span><span class="p">)</span>
<span class="go">​</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Similitud de Jaro entre 2 textos de prueba:&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">s1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;------</span><span class="se">\n</span><span class="s1">Similitudes de Jaro Winkler entre los textos de prueba:&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">s2</span><span class="p">)</span>

<span class="go">Similitud de Jaro entre 2 textos de prueba:</span>
<span class="go">[[0.95238095]]</span>
<span class="go">------</span>
<span class="go">Similitudes de Jaro Winkler entre los textos de prueba:</span>
<span class="go">[[1.         0.96190476 0.2989418  0.30112045]</span>
<span class="go"> [0.96190476 1.         0.2989418  0.30112045]</span>
<span class="go"> [0.2989418  0.2989418  1.         0.90254902]</span>
<span class="go"> [0.30112045 0.30112045 0.90254902 1.        ]]</span>
</pre></div>
</div>
</div>
<div class="section" id="normalizacion-de-medidas-de-distancia">
<h3><span class="section-number">8.4.3. </span>Normalización de medidas de distancia<a class="headerlink" href="#normalizacion-de-medidas-de-distancia" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Para los métodos de distancia (<a class="reference internal" href="../funciones/comparacion.html#comparacion.DiferenciaStrings.distancia_levenshtein" title="comparacion.DiferenciaStrings.distancia_levenshtein"><code class="xref py py-meth docutils literal notranslate"><span class="pre">distancia_levenshtein()</span></code></a>, <a class="reference internal" href="../funciones/comparacion.html#comparacion.DiferenciaStrings.distancia_damerau_levenshtein" title="comparacion.DiferenciaStrings.distancia_damerau_levenshtein"><code class="xref py py-meth docutils literal notranslate"><span class="pre">distancia_damerau_levenshtein()</span></code></a> y <a class="reference internal" href="../funciones/comparacion.html#comparacion.DiferenciaStrings.distancia_hamming" title="comparacion.DiferenciaStrings.distancia_hamming"><code class="xref py py-meth docutils literal notranslate"><span class="pre">distancia_hamming()</span></code></a>) es posible utilizar el parámetro norm, que por defecto es igual a None, para normalizar la distancia calculada.</p>
<p>Si norm=1, se dividirá la distancia encontrada por la longitud (número de caracteres) del texto más corto de los dos a comparar. Si norm=2, se dividirá la distancia encontrada por la longitud (número de caracteres) del texto más largo. En este segundo caso se puede garantizar que el valor resultante será un número entre 0 y 1.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Diferencia entre lista de textos</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d1</span> <span class="o">=</span> <span class="n">dif_strings</span><span class="o">.</span><span class="n">distancia_damerau_levenshtein</span><span class="p">(</span><span class="n">strings</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Normalizar dividiendo por el texto más corto</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d2</span><span class="o">=</span> <span class="n">dif_strings</span><span class="o">.</span><span class="n">distancia_damerau_levenshtein</span><span class="p">(</span><span class="n">strings</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Normalizar dividiendo por el texto más largo (se garantiza que queda entre 0 y 1)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d3</span><span class="o">=</span> <span class="n">dif_strings</span><span class="o">.</span><span class="n">distancia_damerau_levenshtein</span><span class="p">(</span><span class="n">strings</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="go">​​</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Distancia de Damerau Levenshtein, sin normalizar:&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">d1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;------</span><span class="se">\n</span><span class="s1">Distancia de Damerau Levenshtein, dividiendo por longitud de texto corto:&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">d2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;------</span><span class="se">\n</span><span class="s1">Distancia de Damerau Levenshtein, dividiendo por longitud de texto largo:&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">d3</span><span class="p">)</span>

<span class="go">Distancia de Damerau Levenshtein, sin normalizar:</span>
<span class="go">[[ 0.  1. 17. 16.]</span>
<span class="go"> [ 1.  0. 17. 16.]</span>
<span class="go"> [17. 17.  0.  3.]</span>
<span class="go"> [16. 16.  3.  0.]]</span>
<span class="go">------</span>
<span class="go">Distancia de Damerau Levenshtein, dividiendo por longitud de texto corto:</span>
<span class="go">[[0.         0.14285714 2.42857143 2.28571429]</span>
<span class="go"> [0.14285714 0.         2.42857143 2.28571429]</span>
<span class="go"> [2.42857143 2.42857143 0.         0.17647059]</span>
<span class="go"> [2.28571429 2.28571429 0.17647059 0.        ]]</span>
<span class="go">------</span>
<span class="go">Distancia de Damerau Levenshtein, dividiendo por longitud de texto largo:</span>
<span class="go">[[0.         0.14285714 0.94444444 0.94117647]</span>
<span class="go"> [0.14285714 0.         0.94444444 0.94117647]</span>
<span class="go"> [0.94444444 0.94444444 0.         0.16666667]</span>
<span class="go"> [0.94117647 0.94117647 0.16666667 0.        ]]</span>
</pre></div>
</div>
</div>
<div class="section" id="comparaciones-entre-dos-grupos-de-strings-distintos">
<h3><span class="section-number">8.4.4. </span>Comparaciones entre dos grupos de strings distintos<a class="headerlink" href="#comparaciones-entre-dos-grupos-de-strings-distintos" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Como se mencionó anteriormente, es posible comparar dos grupos de textos distintos. Para esto, se deben introducir como argumentos dos listas de textos distintas. Los métodos de la clase <a class="reference internal" href="../funciones/comparacion.html#comparacion.DiferenciaStrings" title="comparacion.DiferenciaStrings"><code class="xref py py-class docutils literal notranslate"><span class="pre">DiferenciaStrings</span></code></a> calcularán la métrica de similitud o distancia indicada entre cada uno de los elementos de la primera lista y cada uno de los elementos de la segunda lista.</p>
<p>Esto aplica para cualquiera de los métodos de la clase <a class="reference internal" href="../funciones/comparacion.html#comparacion.DiferenciaStrings" title="comparacion.DiferenciaStrings"><code class="xref py py-class docutils literal notranslate"><span class="pre">DiferenciaStrings</span></code></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">d1</span> <span class="o">=</span> <span class="n">dif_strings</span><span class="o">.</span><span class="n">distancia_levenshtein</span><span class="p">(</span><span class="n">strings</span><span class="p">,</span> <span class="s1">&#39;pescados&#39;</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s1</span> <span class="o">=</span> <span class="n">dif_strings</span><span class="o">.</span><span class="n">similitud_jaro_winkler</span><span class="p">(</span><span class="n">strings</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;pescador&#39;</span><span class="p">,</span> <span class="s1">&#39;John Díaz&#39;</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Distancias de Levenshtein entre un grupo de strings y otro texto, dividiendo por longitud de texto largo:&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">d1</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-------</span><span class="se">\n</span><span class="s1">Similitudes de Jaro-Winkler entre dos grupos de strings:&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">s1</span><span class="p">)</span>

<span class="go">Distancias de Levenshtein entre un grupo de strings y otro texto, dividiendo por longitud de texto largo:</span>
<span class="go">[[0.125     ]</span>
<span class="go"> [0.375     ]</span>
<span class="go"> [0.94444444]</span>
<span class="go"> [0.88235294]]</span>
<span class="go">-------</span>
<span class="go">Similitudes de Jaro-Winkler entre dos grupos de strings:</span>
<span class="go">[[0.975      0.41798942]</span>
<span class="go"> [0.92857143 0.41798942]</span>
<span class="go"> [0.28703704 0.62698413]</span>
<span class="go"> [0.28921569 0.54989107]]</span>
</pre></div>
</div>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="07_vectorizacion_de_textos.html" title="previous page"><span class="section-number">7. </span>Vectorización de textos</a>
    <a class='right-next' id="next-link" href="09_casos_de_uso.html" title="next page">Casos de uso</a>

              </div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, UCD - DNP.<br/>
</p>
    </div>
    
    <div class="footer-item">
      <p class="last-updated">
Actualizado por última vez en jul. 13, 2021.<br/>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>