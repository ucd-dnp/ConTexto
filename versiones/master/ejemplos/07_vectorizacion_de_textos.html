
<!DOCTYPE html>

<html lang="es">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>7. Vectorización de textos &#8212; documentación de ConTexto - 0.2</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/translations.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Índice" href="../genindex.html" />
    <link rel="search" title="Búsqueda" href="../search.html" />
    <link rel="next" title="8. Comparación de textos" href="08_comparacion_de_textos.html" />
    <link rel="prev" title="6. Stemming de textos" href="06_stemming_de_textos.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/logo_2.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../_primeros_pasos.html">
  Primeros pasos
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../_documentacion.html">
  Documentación
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../genindex.html">
  Índice
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../_contribuciones.html">
  ¿Cómo contribuir?
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../_control_de_cambios.html">
  Control de cambios
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/ucd-dnp/ConTexto/" rel="noopener" target="_blank" title="GitHub ConTexto">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub ConTexto</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="mailto:ucd@dnp.gov.co" rel="noopener" target="_blank" title="Enviar correo">
            <span><i class="far fa-envelope"></i></span>
            <label class="sr-only">Enviar correo</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Buscar en la documentación ..." aria-label="Buscar en la documentación ..." autocomplete="off" >
</form>

<a id="versions_anchor" class="nav-link" data-toggle="collapse" href="#collapseExample" role="button" aria-expanded="false" aria-controls="collapseExample">
    <span class="fa fa-book"></span> Versión
        latest
    

    <span class="fa fa-caret-down"></span>
</a>  

<div class="collapse" id="collapseExample">
    <div class="card card-body">
            <dl>
                <dt>Versiones</dt>
                        <dd><a href="07_vectorizacion_de_textos.html">latest</a></dd>        
                    
            <!-- </dl> -->
            <!-- <dl> -->
                <!-- <dt>Tags</dt> -->

                    
                        <dd><a href="../../v0.1b/ejemplos/07_vectorizacion_de_textos.html">v0.1</a></dd>
                    
            </dl>
    </div>
</div><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <p class="caption">
 <span class="caption-text">
  Primeros pasos:
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../seccion_instalacion.html">
   Instalación
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../seccion_ejemplos.html">
   Ejemplos
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="01_lectura_y_escritura_de_documentos.html">
     1. Lectura y escritura de documentos
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02_limpieza_de_textos.html">
     2. Limpieza de textos
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03_exploracion_y_visualizacion.html">
     3. Análisis exploratorio y visualización
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04_correccion_ortografica.html">
     4. Corrección ortográfica
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="05_lematizacion_de_textos.html">
     5. Lematización de textos
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="06_stemming_de_textos.html">
     6. Stemming de textos
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     7. Vectorización de textos
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08_comparacion_de_textos.html">
     8. Comparación de textos
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="09_casos_de_uso.html">
     Casos de uso
    </a>
   </li>
  </ul>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#importar-paquetes-necesarios-y-adecuar-el-texto-de-prueba">
   7.1. Importar paquetes necesarios y adecuar el texto de prueba
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vectorizaciones-por-frecuencia-de-terminos">
   7.2. Vectorizaciones por frecuencia de términos
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inicializar-y-ajustar-los-vectorizadores">
     7.2.1. Inicializar y ajustar los vectorizadores
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vocabulario-de-los-vectorizadores-ajustados">
     7.2.2. Vocabulario de los vectorizadores ajustados
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vectorizar-textos-utilizando-los-vectorizadores-entrenados">
     7.2.3. Vectorizar textos utilizando los vectorizadores entrenados
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#transformada-inversa-de-un-vector">
     7.2.4. Transformada inversa de un vector
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cargar-un-vectorizador-ajustado-previamente">
     7.2.5. Cargar un vectorizador ajustado previamente
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vectorizacion-por-medio-de-hashing">
   7.3. Vectorización por medio de
   <em>
    Hashing
   </em>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vectorizacion-utilizando-word-embeddings-word2vec">
   7.4. Vectorización utilizando
   <em>
    word embeddings
   </em>
   - Word2Vec
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inicializar-y-aplicar-el-vectorizador">
     7.4.1. Inicializar y aplicar el vectorizador
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#textos-con-palabras-desconocidas-no-incluidas-en-el-modelo">
     7.4.2. Textos con palabras desconocidas (no incluídas en el modelo)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#obtener-palabras-y-vectores-de-un-texto">
     7.4.3. Obtener palabras y vectores de un texto
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#calcular-similitudes-entre-textos">
     7.4.4. Calcular similitudes entre textos
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vectorizacion-utilizando-document-embeddings-doc2vec">
   7.5. Vectorización utilizando
   <em>
    document embeddings
   </em>
   - Doc2Vec
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inicializar-y-entrenar-el-vectorizador">
     7.5.1. Inicializar y entrenar el vectorizador
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vectorizar-textos-utilizando-el-vectorizador">
     7.5.2. Vectorizar textos utilizando el vectorizador
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cargar-un-vectorizador-entrenado-previamente">
     7.5.3. Cargar un vectorizador entrenado previamente
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="vectorizacion-de-textos">
<span id="id1"></span><h1><span class="section-number">7. </span>Vectorización de textos<a class="headerlink" href="#vectorizacion-de-textos" title="Enlazar permanentemente con este título">¶</a></h1>
<p>Este ejemplo muestra las principales funcionalidades del módulo <a class="reference internal" href="../funciones/vectorizacion.html#module-vectorizacion" title="vectorizacion"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Vectorización</span></code></a> de la librería. Este módulo permite generar representaciones vectoriales o numéricas de textos a través de distintas técnicas. La capacidad de representar un texto de forma numérica es muy útil para posteriores análisis de textos. Tales como comparaciones, agrupaciones, entrenamiento de modelos de clasificación, entre otros.</p>
<div class="section" id="importar-paquetes-necesarios-y-adecuar-el-texto-de-prueba">
<h2><span class="section-number">7.1. </span>Importar paquetes necesarios y adecuar el texto de prueba<a class="headerlink" href="#importar-paquetes-necesarios-y-adecuar-el-texto-de-prueba" title="Enlazar permanentemente con este título">¶</a></h2>
<p>El primer paso es importar las funciones del módulo de <a class="reference internal" href="../funciones/vectorizacion.html#module-vectorizacion" title="vectorizacion"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Vectorización</span></code></a> y definir los textos para correr los ejemplos. Adicionalmente, se importan y utilizan las funciones <a class="reference internal" href="../funciones/limpieza.html#limpieza.limpieza_texto" title="limpieza.limpieza_texto"><code class="xref py py-func docutils literal notranslate"><span class="pre">limpieza.limpieza_texto()</span></code></a> y <a class="reference internal" href="../funciones/limpieza.html#limpieza.lista_stopwords" title="limpieza.lista_stopwords"><code class="xref py py-func docutils literal notranslate"><span class="pre">limpieza.lista_stopwords()</span></code></a> del módulo <a class="reference internal" href="../funciones/limpieza.html#module-limpieza" title="limpieza"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Limpieza</span></code></a>, para hacer un procesamiento previo de los textos antes de generar sus representaciones vectoriales.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">contexto.limpieza</span> <span class="kn">import</span> <span class="n">limpieza_texto</span><span class="p">,</span> <span class="n">lista_stopwords</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">contexto.vectorizacion</span> <span class="kn">import</span> <span class="o">*</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Corpus de prueba</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">textos_prueba</span> <span class="o">=</span> <span class="p">[</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="s1">&#39;Este es el primer texto de prueba para la vectorización y sus elementos.&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="s1">&#39;Una segunda oración permite evaluar si hay elementos en común para vectorizar.&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="s1">&#39;Tercera frase que consiste en un texto complementario con palabras comúnmente utilizadas.&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="s1">&#39;En esta oración y la siguiente se introducen elementos para completar un grupo de por lo menos 5.&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="s1">&#39;Finalmente, esta frase cierra un grupo de 5 oraciones para probar la vectorización.&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="s1">&#39;Una última frase para ampliar un poco el grupo.&#39;</span><span class="p">]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Limpieza básica a los textos para quitar ruido</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">textos_limpios</span> <span class="o">=</span> <span class="p">[</span><span class="n">limpieza_texto</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">lista_stopwords</span><span class="p">(),</span> <span class="n">quitar_numeros</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">textos_prueba</span><span class="p">]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Texto que no hace parte del corpus original</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">texto_nuevo</span> <span class="o">=</span> <span class="s1">&#39;hola, este es un texto de prueba. Se desea aplicar la vectorización en este texto.&#39;</span>
</pre></div>
</div>
</div>
<div class="section" id="vectorizaciones-por-frecuencia-de-terminos">
<h2><span class="section-number">7.2. </span>Vectorizaciones por frecuencia de términos<a class="headerlink" href="#vectorizaciones-por-frecuencia-de-terminos" title="Enlazar permanentemente con este título">¶</a></h2>
<p>La clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorFrecuencias" title="vectorizacion.VectorizadorFrecuencias"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorFrecuencias</span></code></a> permite aplicar las técnicas Bag of Words (BOW), Term Frecuency (TF) y Term Frequency – Inverse Document Frequency (TF-IDF) para generar representaciones vectoriales de textos basadas en la frecuencia con la que aparecen ciertas palabras o términos en cada texto.</p>
<div class="section" id="inicializar-y-ajustar-los-vectorizadores">
<h3><span class="section-number">7.2.1. </span>Inicializar y ajustar los vectorizadores<a class="headerlink" href="#inicializar-y-ajustar-los-vectorizadores" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Para utilizar estos tipos de vectorización es necesario definir un objeto de clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorFrecuencias" title="vectorizacion.VectorizadorFrecuencias"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorFrecuencias</span></code></a>, especificando aspectos como:</p>
<ul class="simple">
<li><p>Qué tipo de técnica aplicar (BOW, TF o TF-IDF).</p></li>
<li><p>El rango de n-gramas que se desea tener en cuenta (solo palabras, palabras y bigramas, etc.).</p></li>
<li><p>Si se quiere limitar el tamaño del vocabulario del vectorizador a los <em>n</em> términos más frecuentes. Esto puede ser útil cuando se tienen muchos textos de larga longitud, lo que puede llegar a generar un vocabulario demasiado grande si no se acota.</p></li>
</ul>
<p>Una vez se define el objeto del vectorizador, es necesario ajustarlo sobre un corpus para que aprenda el vocabulario que va a utilizar. Al momento de ajustar el vectorizador se puede utilizar el parámetro <em>archivo_salida</em>. Si este parámetro se utiliza, el vectorizador ajustado va a quedar guardado como un objeto tipo <em>Pickle</em> en la ubicación definida por el usuario.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1">## Inicializar los vectorizadores</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Vectorizador BOW</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_bow</span> <span class="o">=</span> <span class="n">VectorizadorFrecuencias</span><span class="p">()</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Vectorizador TF-IDF. Este tiene en cuenta palabras y bigramas, y solo coge las 20 más frecuentes</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_tfidf</span> <span class="o">=</span> <span class="n">VectorizadorFrecuencias</span><span class="p">(</span><span class="s1">&#39;tfidf&#39;</span><span class="p">,</span> <span class="n">rango_ngramas</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">max_elementos</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1">## Ajustar los vectorizadores</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Se van a guardar los vectorizadores ajustados en archivos para su posterior uso</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_bow</span><span class="o">.</span><span class="n">ajustar</span><span class="p">(</span><span class="n">textos_limpios</span><span class="p">,</span> <span class="n">archivo_salida</span><span class="o">=</span><span class="s1">&#39;salida/v_bow.pk&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_tfidf</span><span class="o">.</span><span class="n">ajustar</span><span class="p">(</span><span class="n">textos_limpios</span><span class="p">,</span> <span class="n">archivo_salida</span><span class="o">=</span><span class="s1">&#39;salida/v_tfidf.pk&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="vocabulario-de-los-vectorizadores-ajustados">
<h3><span class="section-number">7.2.2. </span>Vocabulario de los vectorizadores ajustados<a class="headerlink" href="#vocabulario-de-los-vectorizadores-ajustados" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Una vez cada vectorizador ha sido ajustado, se puede acceder a su vocabulario llamando el método <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorFrecuencias.vocabulario" title="vectorizacion.VectorizadorFrecuencias.vocabulario"><code class="xref py py-meth docutils literal notranslate"><span class="pre">vocabulario()</span></code></a>. Esto retorna un DataFrame de Pandas con el término asignado a cada posición de los vectores resultantes. A continuación se muestran los términos de las primeras 10 posiciones para los dos vectorizadores ajustados.</p>
<p>Se puede observar que <cite>v_tfidf</cite> incluye términos y bigramas, tal y como se estableció al definir esa variable.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1">## Vocabulario de un vectorizador entrenado</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">display</span><span class="p">(</span><span class="n">v_bow</span><span class="o">.</span><span class="n">vocabulario</span><span class="p">()</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">v_tfidf</span><span class="o">.</span><span class="n">vocabulario</span><span class="p">()</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Vocabulario vectorizador BOW</p></li>
</ul>
<table class="table">
<colgroup>
<col style="width: 30%" />
<col style="width: 70%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>posición</p></th>
<th class="head"><p>palabra</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0</p></td>
<td><p>ampliar</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>cierra</p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>complementario</p></td>
</tr>
<tr class="row-odd"><td><p>3</p></td>
<td><p>completar</p></td>
</tr>
<tr class="row-even"><td><p>4</p></td>
<td><p>común</p></td>
</tr>
<tr class="row-odd"><td><p>5</p></td>
<td><p>comúnmente</p></td>
</tr>
<tr class="row-even"><td><p>6</p></td>
<td><p>consiste</p></td>
</tr>
<tr class="row-odd"><td><p>7</p></td>
<td><p>elementos</p></td>
</tr>
<tr class="row-even"><td><p>8</p></td>
<td><p>evaluar</p></td>
</tr>
<tr class="row-odd"><td><p>9</p></td>
<td><p>finalmente</p></td>
</tr>
</tbody>
</table>
<ul class="simple">
<li><p>Vocabulario vectorizador TF-IDF</p></li>
</ul>
<table class="table">
<colgroup>
<col style="width: 30%" />
<col style="width: 70%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>posición</p></th>
<th class="head"><p>palabra</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0</p></td>
<td><p>ampliar</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>elementos</p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>frase</p></td>
</tr>
<tr class="row-odd"><td><p>3</p></td>
<td><p>grupo</p></td>
</tr>
<tr class="row-even"><td><p>4</p></td>
<td><p>oración</p></td>
</tr>
<tr class="row-odd"><td><p>5</p></td>
<td><p>oración permite</p></td>
</tr>
<tr class="row-even"><td><p>6</p></td>
<td><p>oración siguiente</p></td>
</tr>
<tr class="row-odd"><td><p>7</p></td>
<td><p>palabras</p></td>
</tr>
<tr class="row-even"><td><p>8</p></td>
<td><p>palabras comúnmente</p></td>
</tr>
<tr class="row-odd"><td><p>9</p></td>
<td><p>permite</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="vectorizar-textos-utilizando-los-vectorizadores-entrenados">
<h3><span class="section-number">7.2.3. </span>Vectorizar textos utilizando los vectorizadores entrenados<a class="headerlink" href="#vectorizar-textos-utilizando-los-vectorizadores-entrenados" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Una vez se tiene el vectorizador ajustado, la función <cite>vectorizar</cite> permite obtener, para uno o varios textos de entrada, un arreglo (<em>array</em>) en numpy de 2 dimensiones. La cantidad de filas de este arreglo corresponde al número de textos vectorizados, y la cantidad de columnas corresponde al tamaño del vocabulario del vectorizador. El argumento <em>disperso</em> permite  obtener como salida una matriz dispersa (disperso=True) o un arreglo de numpy (disperso=False). Esto puede traducirse en un ahorro significativo de memoria en el caso de que se tengan muchos textos y/o un vocabulario muy grande.</p>
<p>Es importante anotar que si algún texto de entrada tiene palabras que no hacen parte del vocabulario del vectorizador, estas no serán tenidas en cuenta.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">vector_bow</span> <span class="o">=</span> <span class="n">v_bow</span><span class="o">.</span><span class="n">vectorizar</span><span class="p">(</span><span class="n">texto_nuevo</span><span class="p">,</span> <span class="n">disperso</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># Salida como matriz dispersa</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vector_tfidf</span> <span class="o">=</span> <span class="n">v_tfidf</span><span class="o">.</span><span class="n">vectorizar</span><span class="p">(</span><span class="n">texto_nuevo</span><span class="p">,</span> <span class="n">disperso</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># Salida como un numpy array</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;El vector de BOW sale como una matriz dispersa:&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">vector_bow</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">--------&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;El vector de TF-IDF sale como un numpy array:&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Dimensiones de la salida:&#39;</span><span class="p">,</span> <span class="n">vector_tfidf</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">vector_tfidf</span><span class="p">)</span>

<span class="go">El vector de BOW sale como una matriz dispersa:</span>
<span class="go">  (0, 20)   1</span>
<span class="go">  (0, 24)   2</span>
<span class="go">  (0, 26)   1</span>

<span class="go">--------</span>
<span class="go">El vector de TF-IDF sale como un numpy array:</span>
<span class="go">Dimensiones de la salida: (1, 20)</span>
<span class="go">[[0.         0.         0.         0.         0.         0.</span>
<span class="go">  0.         0.         0.         0.         0.         0.</span>
<span class="go">  0.         0.         0.         0.         0.         0.</span>
<span class="go">  0.89442719 0.4472136 ]]</span>
</pre></div>
</div>
</div>
<div class="section" id="transformada-inversa-de-un-vector">
<h3><span class="section-number">7.2.4. </span>Transformada inversa de un vector<a class="headerlink" href="#transformada-inversa-de-un-vector" title="Enlazar permanentemente con este título">¶</a></h3>
<p>La función <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorFrecuencias.inversa" title="vectorizacion.VectorizadorFrecuencias.inversa"><code class="xref py py-func docutils literal notranslate"><span class="pre">inversa()</span></code></a> de la clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorFrecuencias" title="vectorizacion.VectorizadorFrecuencias"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorFrecuencias</span></code></a> permite, a partir de un vector, obtener las palabras que componen el texto representado por dicho vector.</p>
<p>Nótese que al realizar la transformada inversa se pierde el orden de las palabras. Esto se debe a que estos métodos de vectorización no tienen en cuenta el orden sino la frecuencia de aparición de cada término. Además, si un término no está en el vocabulario del vectorizador, no va a estar incluído en el vector y por lo tanto no se podrá recuperar en la transformada
inversa.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">textos_limpios</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">v_bow</span><span class="o">.</span><span class="n">inversa</span><span class="p">(</span><span class="n">v_bow</span><span class="o">.</span><span class="n">vectorizar</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">))[</span><span class="mi">0</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">textos_limpios</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">v_tfidf</span><span class="o">.</span><span class="n">inversa</span><span class="p">(</span><span class="n">v_tfidf</span><span class="o">.</span><span class="n">vectorizar</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">))[</span><span class="mi">2</span><span class="p">])</span>

<span class="go">primer texto prueba vectorización elementos</span>
<span class="go">[&#39;elementos&#39; &#39;primer&#39; &#39;prueba&#39; &#39;texto&#39; &#39;vectorización&#39;]</span>
<span class="go">tercera frase consiste texto complementario palabras comúnmente utilizadas</span>
<span class="go">[&#39;frase&#39; &#39;palabras&#39; &#39;palabras comúnmente&#39; &#39;texto&#39;]</span>
</pre></div>
</div>
</div>
<div class="section" id="cargar-un-vectorizador-ajustado-previamente">
<h3><span class="section-number">7.2.5. </span>Cargar un vectorizador ajustado previamente<a class="headerlink" href="#cargar-un-vectorizador-ajustado-previamente" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Previamente vimos cómo se puede guardar un vectorizador ajustado, por medio del parámetro <em>archivo_salida</em> de la función <cite>ajustar</cite>. Este vectorizador, ya ajustado, se puede cargar y utilizar al momento de definir un nuevo objeto de la clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorFrecuencias" title="vectorizacion.VectorizadorFrecuencias"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorFrecuencias</span></code></a>. Para cargar un vectorizador ajustado previamente se debe utilizar el parámetro <em>archivo_modelo</em>, especificando dónde está el archivo con el vectorizador ya ajustado. Al usar esta opción, los demás parámetros de inicialización no serán tenidos en cuenta, pues esos parámetros se tomarán del vectorizador cargado.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">v_bow_2</span> <span class="o">=</span> <span class="n">VectorizadorFrecuencias</span><span class="p">(</span><span class="n">archivo_modelo</span><span class="o">=</span><span class="s1">&#39;salida/v_bow.pk&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_tfidf_2</span> <span class="o">=</span> <span class="n">VectorizadorFrecuencias</span><span class="p">(</span><span class="n">archivo_modelo</span><span class="o">=</span><span class="s1">&#39;salida/v_tfidf.pk&#39;</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Se vectoriza el mismo texto con los vectorizadores cargados</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vector_bow_2</span> <span class="o">=</span> <span class="n">v_bow_2</span><span class="o">.</span><span class="n">vectorizar</span><span class="p">(</span><span class="n">texto_nuevo</span><span class="p">,</span> <span class="n">disperso</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># Salida como matriz dispersa</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vector_tfidf_2</span> <span class="o">=</span> <span class="n">v_tfidf_2</span><span class="o">.</span><span class="n">vectorizar</span><span class="p">(</span><span class="n">texto_nuevo</span><span class="p">,</span> <span class="n">disperso</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># Salida como un numpy array</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Se comprueba que los vectores resultantes sean iguales</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">vector_bow</span> <span class="o">==</span> <span class="n">vector_bow_2</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">vector_tfidf</span> <span class="o">==</span> <span class="n">vector_tfidf_2</span><span class="p">))</span>

<span class="go">True</span>
<span class="go">True</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="vectorizacion-por-medio-de-hashing">
<h2><span class="section-number">7.3. </span>Vectorización por medio de <em>Hashing</em><a class="headerlink" href="#vectorizacion-por-medio-de-hashing" title="Enlazar permanentemente con este título">¶</a></h2>
<p>La clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorHash" title="vectorizacion.VectorizadorHash"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorHash</span></code></a> utiliza el <em>hashing trick</em> para determinar directamente (sin necesidad de ajustar sobre un corpus) la posición de cada término de un texto dentro de un vector numérico. Esta técnica es rápida y ligera en memoria, pues no requiere aprender ni guardar un vocabulario. Esto también tiene algunas desventajas; por ejemplo, a partir de un vector no se puede aplicar una transformada inversa para conocer qué palabras contenía el texto.</p>
<p>Adicionalmente, cuando se consideran muchos textos, o textos muy grandes, existe la posibilidad de que se presenten “colisiones”. Una colisión se da cuando el vectorizador representa de la misma manera a dos términos distintos, lo cual introduce ambigüedad en la vectorización y disminuye la calidad de la representación numérica de los textos. Para evitar este problema, se puede configurar el objeto de clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorHash" title="vectorizacion.VectorizadorHash"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorHash</span></code></a> para que tenga muchos más elementos (por medio del parámetro <em>n_elementos</em>) a medida que se trabaja con textos de mayor longitud y vocabulario.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1">## Inicializar el vectorizador</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># En este caso se define que los vectores tendrán 50 elementos</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_hash</span> <span class="o">=</span> <span class="n">VectorizadorHash</span><span class="p">(</span><span class="n">n_elementos</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1">## Aplicar el vectorizador directamente a los textos (no hace falta ajustar antes)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vectores_prueba</span> <span class="o">=</span> <span class="n">v_hash</span><span class="o">.</span><span class="n">vectorizar</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dimensiones del grupo de vectores:&quot;</span><span class="p">,</span> <span class="n">vectores_prueba</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># El valor de cada elemento será proporcional a la frecuencia de aparición de un término en el texto</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vector_nuevo</span> <span class="o">=</span> <span class="n">v_hash</span><span class="o">.</span><span class="n">vectorizar</span><span class="p">(</span><span class="n">texto_nuevo</span><span class="p">,</span> <span class="n">disperso</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;----------&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dimensiones del vector:&quot;</span><span class="p">,</span> <span class="n">vector_nuevo</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">vector_nuevo</span><span class="p">)</span>

<span class="go">Dimensiones del grupo de vectores: (6, 50)</span>
<span class="go">----------</span>
<span class="go">Dimensiones del vector: (1, 50)</span>
<span class="go">[[ 0.   0.  -0.2  0.   0.   0.   0.2  0.   0.2  0.   0.   0.   0.   0.</span>
<span class="go">   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.4 -0.2 -0.2</span>
<span class="go">   0.   0.   0.   0.   0.   0.   0.  -0.2  0.   0.  -0.2  0.   0.  -0.4</span>
<span class="go">   0.   0.   0.6  0.   0.   0.2  0.   0. ]]</span>
</pre></div>
</div>
</div>
<div class="section" id="vectorizacion-utilizando-word-embeddings-word2vec">
<h2><span class="section-number">7.4. </span>Vectorización utilizando <em>word embeddings</em> - Word2Vec<a class="headerlink" href="#vectorizacion-utilizando-word-embeddings-word2vec" title="Enlazar permanentemente con este título">¶</a></h2>
<p>La clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorWord2Vec" title="vectorizacion.VectorizadorWord2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorWord2Vec</span></code></a> utiliza por debajo las funcionalidades de la librería
<a class="reference external" href="https://spacy.io/">spaCy</a> para cargar <em>embeddings</em>, o representaciones vectoriales densas, de palabras en diferentes idiomas. Estas <em>embeddings</em> son representaciones de 300 elementos para cada palabra que exista en el diccionario del modelo, y ya han sido previamente entrenadas sobre un corpus de texto muy grande, utilizando técnicas como <em>Word2Vec</em> y <em>GloVe</em>.</p>
<p>La clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorWord2Vec" title="vectorizacion.VectorizadorWord2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorWord2Vec</span></code></a> permite utilizar y acceder a estas representaciones ya entrenadas que, a diferencia de los vectores basados en frecuencias, permiten a través del entrenamiento previo capturar información del contexto de las palabras. De esta manera, las representaciones densas de las palabras “hombre” y “niño” van a ser similares entre sí en ese espacio de 300 dimensiones, mientas que las palabras “hombre” y “cuchara” van a estar más alejadas.</p>
<div class="section" id="inicializar-y-aplicar-el-vectorizador">
<h3><span class="section-number">7.4.1. </span>Inicializar y aplicar el vectorizador<a class="headerlink" href="#inicializar-y-aplicar-el-vectorizador" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Al definir un objeto de la clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorWord2Vec" title="vectorizacion.VectorizadorWord2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorWord2Vec</span></code></a> es necesario definir el lenguaje y el tamaño del modelo que se desea utilizar. De manera similar al caso de lematización, en este caso spaCy tiene modelos de varios tamaños para cada lenguaje. Entre más grande sea el modelo, este contará con vectores para un vocabulario más grande. Los modelos de spaCy que soportan la vectorización son el mediano (“md”) y el grande (“lg”).</p>
<p>Dado que se carga un modelo previamente entrenado, no es necesario ajustar este vectorizador. Al igual que con el <cite>VectorizadorHash</cite>, los objetos de clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorWord2Vec" title="vectorizacion.VectorizadorWord2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorWord2Vec</span></code></a> pueden ser aplicados directamente a una palabra o texto de entrada para obtener su vector. Cuando el texto de entrada tiene dos o más palabras, la función <cite>vectorizar</cite> obtendrá el vector de cada palabra que compone el texto, y luego calculará el promedio de todos los vectores para obtener un único vector de salida.</p>
<div class="admonition note">
<p class="admonition-title">Nota</p>
<p>La primera vez que se utilice una combinación particular de lenguaje + tamaño, la librería descargará el modelo correspondiente en el computador del usuario. Para poder usar este modelo, se debe reiniciar la sesión de Python y correr la función de nuevo.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1">## Inicializar el vectorizador</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_word2vec</span> <span class="o">=</span> <span class="n">VectorizadorWord2Vec</span><span class="p">()</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">## Vectorizar textos utilizando el vectorizador</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vector</span> <span class="o">=</span> <span class="n">v_word2vec</span><span class="o">.</span><span class="n">vectorizar</span><span class="p">(</span><span class="n">texto_nuevo</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dimensiones del vector:&quot;</span><span class="p">,</span> <span class="n">vector</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Primeros 10 elementos del vector:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">vector</span><span class="p">[</span><span class="mi">0</span><span class="p">,:</span><span class="mi">10</span><span class="p">])</span>

<span class="go">Dimensiones del vector: (1, 300)</span>
<span class="go">Primeros 10 elementos del vector:</span>
<span class="go"> [ 0.3364028   0.7943878  -0.5733206   1.1075957   1.1357956  -1.3824669</span>
<span class="go">  0.53068686  0.662284   -0.33499992  0.22997226]</span>
</pre></div>
</div>
</div>
<div class="section" id="textos-con-palabras-desconocidas-no-incluidas-en-el-modelo">
<h3><span class="section-number">7.4.2. </span>Textos con palabras desconocidas (no incluídas en el modelo)<a class="headerlink" href="#textos-con-palabras-desconocidas-no-incluidas-en-el-modelo" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Como se mencionó en la sección anterior, un texto se vectoriza sacando el promedio de los vectores de cada palabra. Por grande que sea el vocabulario del modelo pre-entrenado que se utiliza, es posible que un nuevo texto contenga palabras que no se encuentran en el vocabulario del modelo. En este caso, el método <cite>vectorizar</cite> del objeto de clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorWord2Vec" title="vectorizacion.VectorizadorWord2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorWord2Vec</span></code></a> puede manejar las palabras desconocidas de dos formas distintas.</p>
<p>El argumento booleano <em>quitar_desconocidas</em> en el método <cite>vectorizar</cite>, cuando se hace igual a <em>True</em>, hará que no se tengan en cuenta las palabras que no están incluídas en el modelo. De esta manera, el vector del texto será el promedio de solamente los vectores de palabras que están presentes en el vocabulario del modelo. Cuando este argumento es <em>False</em> (valor por defecto), para cada palabra desconocida se incluirá un vector de solo ceros, lo que afectará el vector promedio resultante.</p>
<p>A continuación se hace la vectorización de 2 textos distintos. En el primer texto todas las palabras hacen parte del vocabulario del modelo, por lo que el valor del parámetro <em>quitar_desconocidas</em> no va a afectar el vector de salida. Por otro lado, el segundo texto tiene 3 palabras desconocidas. En este caso, los valores del vector resultante van a ser ligeramente menores si se utiliza <em>quitar_desconocidas=False</em>, pues los vectores de solo ceros (correspondientes a las palabras desconocidas) afectarán el promedio del vector de salida.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">texto_1</span> <span class="o">=</span> <span class="s1">&#39;En este texto todas las palabras son conocidas, por lo que los resultados deberían ser iguales&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">texto_2</span> <span class="o">=</span> <span class="s1">&#39;En este texto hay asfafgf términos desconocidos FGs&lt;g gsi&lt;gi&lt;sbf&#39;</span>

<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="n">texto_1</span><span class="p">,</span> <span class="n">texto_2</span><span class="p">]):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">------------------&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Texto </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">:&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;&quot;</span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s1">&quot;&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">v1</span> <span class="o">=</span> <span class="n">v_word2vec</span><span class="o">.</span><span class="n">vectorizar</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">quitar_desconocidas</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">v2</span> <span class="o">=</span> <span class="n">v_word2vec</span><span class="o">.</span><span class="n">vectorizar</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">quitar_desconocidas</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Diferencia promedio: </span><span class="si">{</span><span class="p">(</span><span class="n">v1</span> <span class="o">-</span> <span class="n">v2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="go">------------------</span>
<span class="go">Texto 1:</span>
<span class="go">&quot;En este texto todas las palabras son conocidas, por lo que los resultados deberían ser iguales&quot;</span>
<span class="go">Diferencia promedio: 0.0</span>

<span class="go">------------------</span>
<span class="go">Texto 2:</span>
<span class="go">&quot;En este texto hay asfafgf términos desconocidos FGs&lt;g gsi&lt;gi&lt;sbf&quot;</span>
<span class="go">Diferencia promedio: -0.017988834530115128</span>
</pre></div>
</div>
</div>
<div class="section" id="obtener-palabras-y-vectores-de-un-texto">
<h3><span class="section-number">7.4.3. </span>Obtener palabras y vectores de un texto<a class="headerlink" href="#obtener-palabras-y-vectores-de-un-texto" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Si se desea, es posible obtener los vectores correspondientes a las palabras (incluidas en el modelo) que componen un texto. Esto se puede hacer mediante el método <cite>vectores_palabras</cite>, que puede devolver un DataFrame de Pandas o un diccionario de Python con cada palabra del texto y su correspondiente vector.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">df_palabras</span> <span class="o">=</span> <span class="n">v_word2vec</span><span class="o">.</span><span class="n">vectores_palabras</span><span class="p">(</span><span class="n">texto_nuevo</span><span class="p">,</span> <span class="n">tipo</span><span class="o">=</span><span class="s1">&#39;dataframe&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dict_palabras</span> <span class="o">=</span> <span class="n">v_word2vec</span><span class="o">.</span><span class="n">vectores_palabras</span><span class="p">(</span><span class="n">texto_nuevo</span><span class="p">,</span> <span class="n">tipo</span><span class="o">=</span><span class="s1">&#39;diccionario&#39;</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">df_palabras</span>
</pre></div>
</div>
<table class="table">
<colgroup>
<col style="width: 3%" />
<col style="width: 7%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 2%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>index</p></th>
<th class="head"><p>palabra</p></th>
<th class="head"><p>x_1</p></th>
<th class="head"><p>x_2</p></th>
<th class="head"><p>x_3</p></th>
<th class="head"><p>x_4</p></th>
<th class="head"><p>x_5</p></th>
<th class="head"><p>x_6</p></th>
<th class="head"><p>x_7</p></th>
<th class="head"><p>x_8</p></th>
<th class="head"><p>x_9</p></th>
<th class="head"><p>…</p></th>
<th class="head"><p>x_291</p></th>
<th class="head"><p>x_292</p></th>
<th class="head"><p>x_293</p></th>
<th class="head"><p>x_294</p></th>
<th class="head"><p>x_295</p></th>
<th class="head"><p>x_296</p></th>
<th class="head"><p>x_297</p></th>
<th class="head"><p>x_298</p></th>
<th class="head"><p>x_299</p></th>
<th class="head"><p>x_300</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0</p></td>
<td><p>hola</p></td>
<td><p>2.02740</p></td>
<td><p>-1.274000</p></td>
<td><p>-1.36240</p></td>
<td><p>1.66310</p></td>
<td><p>0.923830</p></td>
<td><p>-0.150770</p></td>
<td><p>0.345830</p></td>
<td><p>1.36940</p></td>
<td><p>0.61444</p></td>
<td><p>…</p></td>
<td><p>1.35750</p></td>
<td><p>0.38467</p></td>
<td><p>0.505280</p></td>
<td><p>0.858590</p></td>
<td><p>1.36380</p></td>
<td><p>1.527900</p></td>
<td><p>-1.262800</p></td>
<td><p>0.82706</p></td>
<td><p>-0.85570</p></td>
<td><p>1.188800</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>,</p></td>
<td><p>1.34940</p></td>
<td><p>2.957500</p></td>
<td><p>-0.60029</p></td>
<td><p>-1.40760</p></td>
<td><p>1.909200</p></td>
<td><p>-0.285360</p></td>
<td><p>0.581940</p></td>
<td><p>2.43280</p></td>
<td><p>-1.59410</p></td>
<td><p>…</p></td>
<td><p>-1.31810</p></td>
<td><p>0.24310</p></td>
<td><p>0.353180</p></td>
<td><p>0.727520</p></td>
<td><p>2.83400</p></td>
<td><p>-0.051198</p></td>
<td><p>3.489500</p></td>
<td><p>1.34580</p></td>
<td><p>-2.10970</p></td>
<td><p>-0.455530</p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>este</p></td>
<td><p>-1.18150</p></td>
<td><p>4.074300</p></td>
<td><p>-3.72130</p></td>
<td><p>5.79750</p></td>
<td><p>-1.925600</p></td>
<td><p>-1.465900</p></td>
<td><p>-1.253400</p></td>
<td><p>-0.48991</p></td>
<td><p>-1.67700</p></td>
<td><p>…</p></td>
<td><p>-0.38054</p></td>
<td><p>-1.09720</p></td>
<td><p>-0.531430</p></td>
<td><p>-3.957000</p></td>
<td><p>-0.24913</p></td>
<td><p>-1.922400</p></td>
<td><p>2.318000</p></td>
<td><p>1.02020</p></td>
<td><p>2.88400</p></td>
<td><p>1.210200</p></td>
</tr>
<tr class="row-odd"><td><p>3</p></td>
<td><p>es</p></td>
<td><p>-5.67930</p></td>
<td><p>-1.851200</p></td>
<td><p>-6.46630</p></td>
<td><p>-1.57010</p></td>
<td><p>-1.770900</p></td>
<td><p>-4.910200</p></td>
<td><p>0.362290</p></td>
<td><p>5.48250</p></td>
<td><p>-1.92520</p></td>
<td><p>…</p></td>
<td><p>-7.98300</p></td>
<td><p>-1.78740</p></td>
<td><p>-7.126600</p></td>
<td><p>-1.653700</p></td>
<td><p>2.02190</p></td>
<td><p>3.560900</p></td>
<td><p>-1.280100</p></td>
<td><p>-0.48058</p></td>
<td><p>0.65105</p></td>
<td><p>-2.964400</p></td>
</tr>
<tr class="row-even"><td><p>4</p></td>
<td><p>un</p></td>
<td><p>0.89790</p></td>
<td><p>5.847700</p></td>
<td><p>-8.07040</p></td>
<td><p>8.84070</p></td>
<td><p>-5.782700</p></td>
<td><p>4.143200</p></td>
<td><p>-0.571410</p></td>
<td><p>-0.40119</p></td>
<td><p>-4.93190</p></td>
<td><p>…</p></td>
<td><p>3.62440</p></td>
<td><p>-3.06400</p></td>
<td><p>-0.009281</p></td>
<td><p>-8.710900</p></td>
<td><p>2.13160</p></td>
<td><p>-6.541200</p></td>
<td><p>0.267060</p></td>
<td><p>3.80520</p></td>
<td><p>6.24080</p></td>
<td><p>2.837600</p></td>
</tr>
<tr class="row-odd"><td><p>5</p></td>
<td><p>texto</p></td>
<td><p>-1.28030</p></td>
<td><p>0.235800</p></td>
<td><p>-1.87390</p></td>
<td><p>0.90060</p></td>
<td><p>-0.246720</p></td>
<td><p>-2.607000</p></td>
<td><p>0.063837</p></td>
<td><p>5.56190</p></td>
<td><p>0.33668</p></td>
<td><p>…</p></td>
<td><p>1.07400</p></td>
<td><p>2.13570</p></td>
<td><p>-5.215400</p></td>
<td><p>-2.547800</p></td>
<td><p>-3.13900</p></td>
<td><p>-0.193810</p></td>
<td><p>-1.107400</p></td>
<td><p>0.75978</p></td>
<td><p>0.73341</p></td>
<td><p>0.052985</p></td>
</tr>
<tr class="row-even"><td><p>6</p></td>
<td><p>de</p></td>
<td><p>0.38853</p></td>
<td><p>0.099683</p></td>
<td><p>5.99970</p></td>
<td><p>-0.83435</p></td>
<td><p>3.742600</p></td>
<td><p>-1.322600</p></td>
<td><p>3.394800</p></td>
<td><p>-2.84590</p></td>
<td><p>3.28950</p></td>
<td><p>…</p></td>
<td><p>-7.32290</p></td>
<td><p>-1.18470</p></td>
<td><p>0.010714</p></td>
<td><p>-3.567100</p></td>
<td><p>0.70618</p></td>
<td><p>-1.429100</p></td>
<td><p>-1.557600</p></td>
<td><p>2.12330</p></td>
<td><p>0.92697</p></td>
<td><p>1.500900</p></td>
</tr>
<tr class="row-odd"><td><p>7</p></td>
<td><p>prueba</p></td>
<td><p>1.43410</p></td>
<td><p>1.177200</p></td>
<td><p>-0.87280</p></td>
<td><p>0.85857</p></td>
<td><p>-3.028900</p></td>
<td><p>-1.197400</p></td>
<td><p>0.492080</p></td>
<td><p>1.47920</p></td>
<td><p>-2.09090</p></td>
<td><p>…</p></td>
<td><p>3.26440</p></td>
<td><p>0.39533</p></td>
<td><p>1.870100</p></td>
<td><p>-1.900300</p></td>
<td><p>2.28250</p></td>
<td><p>-0.399500</p></td>
<td><p>-0.059084</p></td>
<td><p>0.11512</p></td>
<td><p>-1.33580</p></td>
<td><p>-1.433700</p></td>
</tr>
<tr class="row-even"><td><p>8</p></td>
<td><p>.</p></td>
<td><p>1.65170</p></td>
<td><p>-1.963400</p></td>
<td><p>-0.60317</p></td>
<td><p>-1.44970</p></td>
<td><p>-4.645600</p></td>
<td><p>-2.654800</p></td>
<td><p>1.787100</p></td>
<td><p>2.00860</p></td>
<td><p>2.55950</p></td>
<td><p>…</p></td>
<td><p>-2.95930</p></td>
<td><p>0.74480</p></td>
<td><p>2.189800</p></td>
<td><p>0.798260</p></td>
<td><p>2.64470</p></td>
<td><p>-1.984700</p></td>
<td><p>-3.354100</p></td>
<td><p>-0.39062</p></td>
<td><p>-1.83260</p></td>
<td><p>-3.034700</p></td>
</tr>
<tr class="row-odd"><td><p>9</p></td>
<td><p>Se</p></td>
<td><p>3.44230</p></td>
<td><p>3.517600</p></td>
<td><p>-0.98323</p></td>
<td><p>9.61150</p></td>
<td><p>21.457001</p></td>
<td><p>1.370800</p></td>
<td><p>9.016600</p></td>
<td><p>-7.84960</p></td>
<td><p>-6.47540</p></td>
<td><p>…</p></td>
<td><p>1.33140</p></td>
<td><p>-9.96640</p></td>
<td><p>-2.405100</p></td>
<td><p>6.446200</p></td>
<td><p>-8.91220</p></td>
<td><p>11.387000</p></td>
<td><p>1.724500</p></td>
<td><p>-1.94600</p></td>
<td><p>-2.71580</p></td>
<td><p>2.913400</p></td>
</tr>
<tr class="row-even"><td><p>10</p></td>
<td><p>desea</p></td>
<td><p>-4.29940</p></td>
<td><p>1.219600</p></td>
<td><p>0.87215</p></td>
<td><p>-0.35671</p></td>
<td><p>0.492250</p></td>
<td><p>-1.972400</p></td>
<td><p>-0.203840</p></td>
<td><p>7.01900</p></td>
<td><p>3.22810</p></td>
<td><p>…</p></td>
<td><p>1.99170</p></td>
<td><p>-3.23270</p></td>
<td><p>-1.868300</p></td>
<td><p>-1.517700</p></td>
<td><p>0.66831</p></td>
<td><p>0.154560</p></td>
<td><p>-3.252000</p></td>
<td><p>0.28146</p></td>
<td><p>1.07270</p></td>
<td><p>-1.384100</p></td>
</tr>
<tr class="row-odd"><td><p>11</p></td>
<td><p>aplicar</p></td>
<td><p>-1.40740</p></td>
<td><p>1.299100</p></td>
<td><p>2.13120</p></td>
<td><p>0.30753</p></td>
<td><p>-0.928430</p></td>
<td><p>-0.020372</p></td>
<td><p>-2.409200</p></td>
<td><p>0.80072</p></td>
<td><p>-1.60250</p></td>
<td><p>…</p></td>
<td><p>-0.57665</p></td>
<td><p>2.95660</p></td>
<td><p>0.028279</p></td>
<td><p>-0.052178</p></td>
<td><p>-2.21730</p></td>
<td><p>-1.184800</p></td>
<td><p>-1.614600</p></td>
<td><p>-0.92878</p></td>
<td><p>-2.93960</p></td>
<td><p>-1.921600</p></td>
</tr>
<tr class="row-even"><td><p>12</p></td>
<td><p>la</p></td>
<td><p>4.81890</p></td>
<td><p>-1.975100</p></td>
<td><p>3.98690</p></td>
<td><p>-9.48320</p></td>
<td><p>14.446000</p></td>
<td><p>-7.265700</p></td>
<td><p>2.178200</p></td>
<td><p>-8.03830</p></td>
<td><p>6.41720</p></td>
<td><p>…</p></td>
<td><p>-0.94738</p></td>
<td><p>2.05770</p></td>
<td><p>-5.546100</p></td>
<td><p>5.935200</p></td>
<td><p>-0.55970</p></td>
<td><p>2.730500</p></td>
<td><p>-4.170200</p></td>
<td><p>-0.59639</p></td>
<td><p>0.24436</p></td>
<td><p>2.381200</p></td>
</tr>
<tr class="row-odd"><td><p>13</p></td>
<td><p>vectorización</p></td>
<td><p>-0.28528</p></td>
<td><p>1.867000</p></td>
<td><p>0.71944</p></td>
<td><p>-0.46232</p></td>
<td><p>0.076307</p></td>
<td><p>-2.183900</p></td>
<td><p>-1.985400</p></td>
<td><p>1.27820</p></td>
<td><p>-1.78520</p></td>
<td><p>…</p></td>
<td><p>0.90734</p></td>
<td><p>1.39140</p></td>
<td><p>-2.335200</p></td>
<td><p>1.182900</p></td>
<td><p>-1.13460</p></td>
<td><p>-0.324270</p></td>
<td><p>0.553240</p></td>
<td><p>-0.17405</p></td>
<td><p>-1.53170</p></td>
<td><p>-1.541200</p></td>
</tr>
<tr class="row-even"><td><p>14</p></td>
<td><p>en</p></td>
<td><p>4.98830</p></td>
<td><p>-3.279500</p></td>
<td><p>6.72300</p></td>
<td><p>2.27280</p></td>
<td><p>2.543900</p></td>
<td><p>2.365700</p></td>
<td><p>-2.844600</p></td>
<td><p>-2.96690</p></td>
<td><p>-1.61240</p></td>
<td><p>…</p></td>
<td><p>-1.73490</p></td>
<td><p>-0.80675</p></td>
<td><p>1.798400</p></td>
<td><p>1.553700</p></td>
<td><p>9.86970</p></td>
<td><p>0.683280</p></td>
<td><p>3.565700</p></td>
<td><p>3.63670</p></td>
<td><p>4.76150</p></td>
<td><p>-0.695040</p></td>
</tr>
<tr class="row-odd"><td><p>15</p></td>
<td><p>este</p></td>
<td><p>-1.18150</p></td>
<td><p>4.074300</p></td>
<td><p>-3.72130</p></td>
<td><p>5.79750</p></td>
<td><p>-1.925600</p></td>
<td><p>-1.465900</p></td>
<td><p>-1.253400</p></td>
<td><p>-0.48991</p></td>
<td><p>-1.67700</p></td>
<td><p>…</p></td>
<td><p>-0.38054</p></td>
<td><p>-1.09720</p></td>
<td><p>-0.531430</p></td>
<td><p>-3.957000</p></td>
<td><p>-0.24913</p></td>
<td><p>-1.922400</p></td>
<td><p>2.318000</p></td>
<td><p>1.02020</p></td>
<td><p>2.88400</p></td>
<td><p>1.210200</p></td>
</tr>
<tr class="row-even"><td><p>16</p></td>
<td><p>texto</p></td>
<td><p>-1.28030</p></td>
<td><p>0.235800</p></td>
<td><p>-1.87390</p></td>
<td><p>0.90060</p></td>
<td><p>-0.246720</p></td>
<td><p>-2.607000</p></td>
<td><p>0.063837</p></td>
<td><p>5.56190</p></td>
<td><p>0.33668</p></td>
<td><p>…</p></td>
<td><p>1.07400</p></td>
<td><p>2.13570</p></td>
<td><p>-5.215400</p></td>
<td><p>-2.547800</p></td>
<td><p>-3.13900</p></td>
<td><p>-0.193810</p></td>
<td><p>-1.107400</p></td>
<td><p>0.75978</p></td>
<td><p>0.73341</p></td>
<td><p>0.052985</p></td>
</tr>
<tr class="row-odd"><td><p>17</p></td>
<td><p>.</p></td>
<td><p>1.65170</p></td>
<td><p>-1.963400</p></td>
<td><p>-0.60317</p></td>
<td><p>-1.44970</p></td>
<td><p>-4.645600</p></td>
<td><p>-2.654800</p></td>
<td><p>1.787100</p></td>
<td><p>2.00860</p></td>
<td><p>2.55950</p></td>
<td><p>…</p></td>
<td><p>-2.95930</p></td>
<td><p>0.74480</p></td>
<td><p>2.189800</p></td>
<td><p>0.798260</p></td>
<td><p>2.64470</p></td>
<td><p>-1.984700</p></td>
<td><p>-3.354100</p></td>
<td><p>-0.39062</p></td>
<td><p>-1.83260</p></td>
<td><p>-3.034700</p></td>
</tr>
</tbody>
</table>
<p>18 rows × 301 columns</p>
</div>
<div class="section" id="calcular-similitudes-entre-textos">
<h3><span class="section-number">7.4.4. </span>Calcular similitudes entre textos<a class="headerlink" href="#calcular-similitudes-entre-textos" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Finalmente, y aunque hay un módulo de <strong>ConTexto</strong> dedicado exclusivamente al cálculo de distancias y similitudes entre textos, los objetos de la clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorWord2Vec" title="vectorizacion.VectorizadorWord2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorWord2Vec</span></code></a> cuentan con la función <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorWord2Vec.similitud_textos" title="vectorizacion.VectorizadorWord2Vec.similitud_textos"><code class="xref py py-func docutils literal notranslate"><span class="pre">similitud_textos()</span></code></a>, para medir la similitud entre dos palabras o textos.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1">## 3.5 Similitudes entre textos</span>
<span class="gp">&gt;&gt;&gt; </span><span class="sd">&#39;&#39;&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="sd">Esta función aprovecha las facilidades de la librería Spacy para medir la</span>
<span class="gp">&gt;&gt;&gt; </span><span class="sd">similaridad entre 2 palabras o textos.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="sd">&#39;&#39;&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t1</span> <span class="o">=</span> <span class="s1">&#39;los perros y los gatos suelen pelear mucho.&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t2</span> <span class="o">=</span> <span class="s1">&#39;caninos y felinos entran en disputas con frecuencia.&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t3</span> <span class="o">=</span> <span class="s1">&#39;este tercer texto habla sobre un tema distinto a los otros dos&#39;</span>

<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="p">[</span><span class="n">t2</span><span class="p">,</span> <span class="n">t3</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">j</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>            <span class="n">similitud</span> <span class="o">=</span> <span class="n">v_word2vec</span><span class="o">.</span><span class="n">similitud_textos</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-----------------------&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Texto 1: </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Texto 2: </span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Similitud entre textos: </span><span class="si">{</span><span class="n">similitud</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="go">-----------------------</span>
<span class="go">Texto 1: los perros y los gatos suelen pelear mucho.</span>
<span class="go">Texto 2: caninos y felinos entran en disputas con frecuencia.</span>
<span class="go">Similitud entre textos: 0.6875509408308378</span>
<span class="go">-----------------------</span>
<span class="go">Texto 1: los perros y los gatos suelen pelear mucho.</span>
<span class="go">Texto 2: este tercer texto habla sobre un tema distinto a los otros dos</span>
<span class="go">Similitud entre textos: 0.5168476867313971</span>
<span class="go">-----------------------</span>
<span class="go">Texto 1: caninos y felinos entran en disputas con frecuencia.</span>
<span class="go">Texto 2: este tercer texto habla sobre un tema distinto a los otros dos</span>
<span class="go">Similitud entre textos: 0.4299091504956323</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="vectorizacion-utilizando-document-embeddings-doc2vec">
<h2><span class="section-number">7.5. </span>Vectorización utilizando <em>document embeddings</em> - Doc2Vec<a class="headerlink" href="#vectorizacion-utilizando-document-embeddings-doc2vec" title="Enlazar permanentemente con este título">¶</a></h2>
<p>La clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorDoc2Vec" title="vectorizacion.VectorizadorDoc2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorDoc2Vec</span></code></a> utiliza por debajo las funcionalidades de la librería
<a class="reference external" href="https://radimrehurek.com/gensim/">Gensim</a> para entrenar un vectorizador en un corpus o conjunto de textos, de manera que sea capaz de representar documentos mediante <em>embeddings</em>, o representaciones vectoriales densas. Estas <em>embeddings</em> son representaciones de un número de elementos definido por el usuario. Tanto para entrenar el vectorizador como para utilizarlo posteriormente, es necesario hacer un procesamiento sobre los textos de entrada. Las funciones internas de la clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorDoc2Vec" title="vectorizacion.VectorizadorDoc2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorDoc2Vec</span></code></a> se encargan de este procesamiento.</p>
<div class="section" id="inicializar-y-entrenar-el-vectorizador">
<h3><span class="section-number">7.5.1. </span>Inicializar y entrenar el vectorizador<a class="headerlink" href="#inicializar-y-entrenar-el-vectorizador" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Al igual que los vectorizadores basados en frecuencias (<a class="reference external" href="07_vectorizacion_de_textos.html#vectorizaciones-por-frecuencia-de-terminos">ver sección</a>), los objetos de clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorDoc2Vec" title="vectorizacion.VectorizadorDoc2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorDoc2Vec</span></code></a> deben ser entrenados o ajustados sobre un corpus de textos. El primer paso es inicializar el objeto del vectorizador, para esto se deben definir los siguientes parámetros:</p>
<ul class="simple">
<li><p>Número de elementos que tendrán los vectores</p></li>
<li><p>Frecuencia mínima que debe tener cada término en el corpus para ser tenido en cuenta en el modelo. Esto se utiliza para evitar que términos muy poco frecuentes afecten el entrenamiento.</p></li>
<li><p>Número de iteraciones (épocas) que realiza la red neuronal al entrenar el modelo.</p></li>
</ul>
<p>En este ejemplo el corpus de entrenamiento es muy pequeño (5 textos cortos), y ninguna palabra cumple con el parámetro <em>minima_cuenta=5</em> (valor por defecto). Esto puede generar errores, por lo que en este caso se cambia este parámetro a 1 (valor mínimo).</p>
<p>Adicionalmente, al entrenar el vectorizador, por medio del método <cite>entrenar_modelo</cite>, se utiliza el parámetro <em>archivo_salida</em> (opcional) para guardar el modelo entrenado en la ubicación establecida por el usuario.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1">## Inicializar el vectorizador</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Se configura para que tenga 100 elementos y se entrene por 25 épocas</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_doc2vec</span> <span class="o">=</span> <span class="n">VectorizadorDoc2Vec</span><span class="p">(</span><span class="n">n_elementos</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">epocas</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">minima_cuenta</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1">## Entrenar el modelo en un corpus</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_doc2vec</span><span class="o">.</span><span class="n">entrenar_modelo</span><span class="p">(</span><span class="n">textos_limpios</span><span class="p">,</span> <span class="n">archivo_salida</span><span class="o">=</span><span class="s1">&#39;salida/v_doc2vec.pk&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="vectorizar-textos-utilizando-el-vectorizador">
<h3><span class="section-number">7.5.2. </span>Vectorizar textos utilizando el vectorizador<a class="headerlink" href="#vectorizar-textos-utilizando-el-vectorizador" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Al igual que con los otros vectorizadores, el método <cite>vectorizar</cite> acepta un texto o una lista de textos como entrada y devuelve un arreglo numpy de dos dimensiones con los vectores generados. Normalmente, esta operación de vectorización puede producir diferentes vectores para un mismo texto de entrada, que aunque tienen valores distintos, son similares entre sí en el espacio <em>n_elementos</em>-dimensional.</p>
<p>Sin embargo, la clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorDoc2Vec" title="vectorizacion.VectorizadorDoc2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorDoc2Vec</span></code></a> cuenta con una semilla para asegurar que siempre se obtenga el mismo vector para el mismo texto de entrada.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">vector</span> <span class="o">=</span> <span class="n">v_doc2vec</span><span class="o">.</span><span class="n">vectorizar</span><span class="p">(</span><span class="n">texto_nuevo</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dimensiones del vector:&quot;</span><span class="p">,</span> <span class="n">vector</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Primeros 10 elementos del vector:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">vector</span><span class="p">[</span><span class="mi">0</span><span class="p">,:</span><span class="mi">10</span><span class="p">])</span>

<span class="go">Dimensiones del vector: (1, 100)</span>
<span class="go">Primeros 10 elementos del vector:</span>
<span class="go"> [ 0.00011651 -0.00289909 -0.00298333 -0.00355879  0.00197437  0.00171644</span>
<span class="go">  0.00276862  0.00240826  0.00056794 -0.00210888]</span>
</pre></div>
</div>
</div>
<div class="section" id="cargar-un-vectorizador-entrenado-previamente">
<h3><span class="section-number">7.5.3. </span>Cargar un vectorizador entrenado previamente<a class="headerlink" href="#cargar-un-vectorizador-entrenado-previamente" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Previamente vimos cómo se puede guardar un vectorizador entrenado, por medio del parámetro <em>archivo_salida</em> de la función <cite>entrenar_modelo</cite>. Este vectorizador, ya ajustado, se puede cargar y utilizar, al momento de definir un nuevo objeto de la clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorDoc2Vec" title="vectorizacion.VectorizadorDoc2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorDoc2Vec</span></code></a>. Para cargar un vectorizador ajustado previamente se debe utilizar el parámetro <em>archivo_modelo</em>, especificando dónde está el archivo con el vectorizador ya ajustado. Al usar esta opción, los demás parámetros de inicialización no serán tenidos en cuenta, pues esos parámetros se tomarán del vectorizador cargado.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1">## Cargar un vectorizador entrenado previamente</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_doc2vec_2</span> <span class="o">=</span> <span class="n">VectorizadorDoc2Vec</span><span class="p">(</span><span class="n">archivo_modelo</span><span class="o">=</span><span class="s1">&#39;salida/v_doc2vec.pk&#39;</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Se vectoriza el mismo texto con el vectorizador cargado</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vector_2</span> <span class="o">=</span> <span class="n">v_doc2vec_2</span><span class="o">.</span><span class="n">vectorizar</span><span class="p">(</span><span class="n">texto_nuevo</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Se comprueba que ambos vectores resultantes sean iguales</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">vector</span> <span class="o">==</span> <span class="n">vector_2</span><span class="p">)</span>

<span class="go">True</span>
</pre></div>
</div>
</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="06_stemming_de_textos.html" title="previous page"><span class="section-number">6. </span>Stemming de textos</a>
    <a class='right-next' id="next-link" href="08_comparacion_de_textos.html" title="next page"><span class="section-number">8. </span>Comparación de textos</a>

              </div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, UCD - DNP.<br/>
</p>
    </div>
    
    <div class="footer-item">
      <p class="last-updated">
Actualizado por última vez en jul. 13, 2021.<br/>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>