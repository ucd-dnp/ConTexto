

<!DOCTYPE html>
<html class="writer-html5" lang="es" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>7. Vectorización de textos &mdash; documentación de ConTexto - 0.1</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
        <script src="../_static/translations.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Índice" href="../genindex.html" />
    <link rel="search" title="Búsqueda" href="../search.html" />
    <link rel="next" title="8. Comparación de textos" href="08_comparacion_de_textos.html" />
    <link rel="prev" title="6. Stemming de textos" href="06_stemming_de_textos.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> ConTexto
          

          
            
            <img src="../_static/logo_400.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                latest - v0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">ConTexto:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../seccion_introduccion.html">Introducción</a></li>
<li class="toctree-l1"><a class="reference internal" href="../seccion_instalacion.html">Instalación</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../seccion_ejemplos.html">Ejemplos</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01_lectura_y_escritura_de_documentos.html">1. Lectura y escritura de documentos</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_limpieza_de_textos.html">2. Limpieza de textos</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_exploracion_y_visualizacion.html">3. Análisis exploratorio y visualización</a></li>
<li class="toctree-l2"><a class="reference internal" href="04_correccion_ortografica.html">4. Corrección ortográfica</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_lematizacion_de_textos.html">5. Lematización de textos</a></li>
<li class="toctree-l2"><a class="reference internal" href="06_stemming_de_textos.html">6. Stemming de textos</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">7. Vectorización de textos</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#importar-paquetes-necesarios-y-adecuar-el-texto-de-prueba">7.1. Importar paquetes necesarios y adecuar el texto de prueba</a></li>
<li class="toctree-l3"><a class="reference internal" href="#vectorizaciones-por-frecuencia-de-terminos">7.2. Vectorizaciones por frecuencia de términos</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#inicializar-y-ajustar-los-vectorizadores">7.2.1. Inicializar y ajustar los vectorizadores</a></li>
<li class="toctree-l4"><a class="reference internal" href="#vocabulario-de-los-vectorizadores-ajustados">7.2.2. Vocabulario de los vectorizadores ajustados</a></li>
<li class="toctree-l4"><a class="reference internal" href="#vectorizar-textos-utilizando-los-vectorizadores-entrenados">7.2.3. Vectorizar textos utilizando los vectorizadores entrenados</a></li>
<li class="toctree-l4"><a class="reference internal" href="#transformada-inversa-de-un-vector">7.2.4. Transformada inversa de un vector</a></li>
<li class="toctree-l4"><a class="reference internal" href="#cargar-un-vectorizador-ajustado-previamente">7.2.5. Cargar un vectorizador ajustado previamente</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#vectorizacion-por-medio-de-hashing">7.3. Vectorización por medio de <em>Hashing</em></a></li>
<li class="toctree-l3"><a class="reference internal" href="#vectorizacion-utilizando-word-embeddings-word2vec">7.4. Vectorización utilizando <em>word embeddings</em> - Word2Vec</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#inicializar-y-aplicar-el-vectorizador">7.4.1. Inicializar y aplicar el vectorizador</a></li>
<li class="toctree-l4"><a class="reference internal" href="#textos-con-palabras-desconocidas-no-incluidas-en-el-modelo">7.4.2. Textos con palabras desconocidas (no incluídas en el modelo)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#obtener-palabras-y-vectores-de-un-texto">7.4.3. Obtener palabras y vectores de un texto</a></li>
<li class="toctree-l4"><a class="reference internal" href="#calcular-similitudes-entre-textos">7.4.4. Calcular similitudes entre textos</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#vectorizacion-utilizando-document-embeddings-doc2vec">7.5. Vectorización utilizando <em>document embeddings</em> - Doc2Vec</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#inicializar-y-entrenar-el-vectorizador">7.5.1. Inicializar y entrenar el vectorizador</a></li>
<li class="toctree-l4"><a class="reference internal" href="#vectorizar-textos-utilizando-el-vectorizador">7.5.2. Vectorizar textos utilizando el vectorizador</a></li>
<li class="toctree-l4"><a class="reference internal" href="#cargar-un-vectorizador-entrenado-previamente">7.5.3. Cargar un vectorizador entrenado previamente</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="08_comparacion_de_textos.html">8. Comparación de textos</a></li>
<li class="toctree-l2"><a class="reference internal" href="09_casos_de_uso.html">Casos de uso</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../seccion_lenguajes_soportados.html">Lenguajes soportados</a></li>
<li class="toctree-l1"><a class="reference internal" href="../seccion_ocr.html">OCR</a></li>
</ul>
<p class="caption"><span class="caption-text">Módulos y funciones:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../funciones/comparacion.html">Comparación</a></li>
<li class="toctree-l1"><a class="reference internal" href="../funciones/correccion.html">Corrección</a></li>
<li class="toctree-l1"><a class="reference internal" href="../funciones/escritura.html">Escritura</a></li>
<li class="toctree-l1"><a class="reference internal" href="../funciones/exploracion.html">Exploración</a></li>
<li class="toctree-l1"><a class="reference internal" href="../funciones/lectura.html">Lectura</a></li>
<li class="toctree-l1"><a class="reference internal" href="../funciones/lematizacion.html">Lematización</a></li>
<li class="toctree-l1"><a class="reference internal" href="../funciones/lenguajes.html">Lenguajes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../funciones/limpieza.html">Limpieza</a></li>
<li class="toctree-l1"><a class="reference internal" href="../funciones/stemming.html">Stemming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../funciones/vectorizacion.html">Vectorización</a></li>
<li class="toctree-l1"><a class="reference internal" href="../funciones/utils.html">Utils</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">ConTexto</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../seccion_ejemplos.html">Ejemplos</a> &raquo;</li>
        
      <li><span class="section-number">7. </span>Vectorización de textos</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="vectorizacion-de-textos">
<span id="id1"></span><h1><span class="section-number">7. </span>Vectorización de textos<a class="headerlink" href="#vectorizacion-de-textos" title="Enlazar permanentemente con este título">¶</a></h1>
<p>Este ejemplo muestra las principales funcionalidades del módulo <a class="reference internal" href="../funciones/vectorizacion.html#module-vectorizacion" title="vectorizacion"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Vectorización</span></code></a> de la librería. Este módulo permite generar representaciones vectoriales o numéricas de textos a través de distintas técnicas. La capacidad de representar un texto de forma numérica es muy útil para análisis posteriores de textos, tales como comparaciones, agrupaciones, entrenamiento de modelos de clasificación, entre otros.</p>
<div class="section" id="importar-paquetes-necesarios-y-adecuar-el-texto-de-prueba">
<h2><span class="section-number">7.1. </span>Importar paquetes necesarios y adecuar el texto de prueba<a class="headerlink" href="#importar-paquetes-necesarios-y-adecuar-el-texto-de-prueba" title="Enlazar permanentemente con este título">¶</a></h2>
<p>El primer paso es importar las funciones del módulo de <a class="reference internal" href="../funciones/vectorizacion.html#module-vectorizacion" title="vectorizacion"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Vectorización</span></code></a>, y definir los textos para correr los ejemplos. Adicionalmente, se importan y utilizan las funciones <a class="reference internal" href="../funciones/limpieza.html#limpieza.limpieza_texto" title="limpieza.limpieza_texto"><code class="xref py py-func docutils literal notranslate"><span class="pre">limpieza.limpieza_texto()</span></code></a> y <a class="reference internal" href="../funciones/limpieza.html#limpieza.lista_stopwords" title="limpieza.lista_stopwords"><code class="xref py py-func docutils literal notranslate"><span class="pre">limpieza.lista_stopwords()</span></code></a> del módulo <a class="reference internal" href="../funciones/limpieza.html#module-limpieza" title="limpieza"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Limpieza</span></code></a>, para hacer un procesamiento previo de los textos, antes de generar sus representaciones vectoriales.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">contexto.limpieza</span> <span class="kn">import</span> <span class="n">limpieza_texto</span><span class="p">,</span> <span class="n">lista_stopwords</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">contexto.vectorizacion</span> <span class="kn">import</span> <span class="o">*</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Corpus de prueba</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">textos_prueba</span> <span class="o">=</span> <span class="p">[</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="s1">&#39;Este es el primer texto de prueba para la vectorización y sus elementos.&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="s1">&#39;Una segunda oración permite evaluar si hay elementos en común para vectorizar.&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="s1">&#39;Tercera frase que consiste en un texto complementario con palabras comúnmente utilizadas.&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="s1">&#39;En esta oración y la siguiente se introducen elementos para completar un grupo de por lo menos 5.&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="s1">&#39;Finalmente, esta frase cierra un grupo de 5 oraciones para probar la vectorización.&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="s1">&#39;Una última frase para ampliar un poco el grupo.&#39;</span><span class="p">]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Limpieza básica a los textos para quitar ruido</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">textos_limpios</span> <span class="o">=</span> <span class="p">[</span><span class="n">limpieza_texto</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">lista_stopwords</span><span class="p">(),</span> <span class="n">quitar_numeros</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">textos_prueba</span><span class="p">]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Texto que no hace parte del corpus original</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">texto_nuevo</span> <span class="o">=</span> <span class="s1">&#39;hola, este es un texto de prueba. Se desea aplicar la vectorización en este texto.&#39;</span>
</pre></div>
</div>
</div>
<div class="section" id="vectorizaciones-por-frecuencia-de-terminos">
<h2><span class="section-number">7.2. </span>Vectorizaciones por frecuencia de términos<a class="headerlink" href="#vectorizaciones-por-frecuencia-de-terminos" title="Enlazar permanentemente con este título">¶</a></h2>
<p>La clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorFrecuencias" title="vectorizacion.VectorizadorFrecuencias"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorFrecuencias</span></code></a> permite aplicar las técnicas Bag of Words (BOW), Term Frecuency (TF) y Term Frequency – Inverse Document Frequency (TF-IDF) para generar representaciones vectoriales de textos basadas en la frecuencia con la que aparecen ciertas palabras o términos en cada texto.</p>
<div class="section" id="inicializar-y-ajustar-los-vectorizadores">
<h3><span class="section-number">7.2.1. </span>Inicializar y ajustar los vectorizadores<a class="headerlink" href="#inicializar-y-ajustar-los-vectorizadores" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Para utilizar estos tipos de vectorización, es necesario definir un objeto de clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorFrecuencias" title="vectorizacion.VectorizadorFrecuencias"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorFrecuencias</span></code></a>, especificando aspector tales como:</p>
<ul class="simple">
<li>Qué tipo de técnica aplicar (BOW, TF o TF-IDF).</li>
<li>El rango de n-gramas que se desea tener en cuenta (solo palabras, palabras y bigramas, etc.).</li>
<li>Si se quiere limitar el tamaño del vocabulario del vectorizador a los <em>n</em> términos más frecuentes. Esto puede ser útil cuando se tienen muchos textos de larga longitud, lo que puede llegar a generar un vocabulario demasiado grande si no se acota.</li>
</ul>
<p>Una vez se define el objeto del vectorizador, es necesario ajustarlo sobre un corpus, para que aprenda el vocabulario que va a utilizar. Al momento de ajustar el vectorizador se puede utilizar el parámetro <em>archivo_salida</em>. Si este parámetro se utiliza, el vectorizador ajustado va a quedar guardado como un objeto tipo Pickle en la ubicación definida por el usuario.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1">## Inicializar los vectorizadores</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Vectorizador BOW</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_bow</span> <span class="o">=</span> <span class="n">VectorizadorFrecuencias</span><span class="p">()</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Vectorizador TF-IDF. Este tiene en cuenta palabras y bigramas, y solo coge las 20 más frecuentes</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_tfidf</span> <span class="o">=</span> <span class="n">VectorizadorFrecuencias</span><span class="p">(</span><span class="s1">&#39;tfidf&#39;</span><span class="p">,</span> <span class="n">rango_ngramas</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">max_elementos</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1">## Ajustar los vectorizadores</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Se van a guardar los vectorizadores ajustados en archivos para su posterior uso</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_bow</span><span class="o">.</span><span class="n">ajustar</span><span class="p">(</span><span class="n">textos_limpios</span><span class="p">,</span> <span class="n">archivo_salida</span><span class="o">=</span><span class="s1">&#39;salida/v_bow.pk&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_tfidf</span><span class="o">.</span><span class="n">ajustar</span><span class="p">(</span><span class="n">textos_limpios</span><span class="p">,</span> <span class="n">archivo_salida</span><span class="o">=</span><span class="s1">&#39;salida/v_tfidf.pk&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="vocabulario-de-los-vectorizadores-ajustados">
<h3><span class="section-number">7.2.2. </span>Vocabulario de los vectorizadores ajustados<a class="headerlink" href="#vocabulario-de-los-vectorizadores-ajustados" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Una vez cada vectorizador ha sido ajustado, se puede acceder a su vocabulario llamando el método <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorFrecuencias.vocabulario" title="vectorizacion.VectorizadorFrecuencias.vocabulario"><code class="xref py py-meth docutils literal notranslate"><span class="pre">vocabulario()</span></code></a>. Esto retorna una DataFrame de Pandas con el término asignado a cada posición de los vectores resultantes. A continuación se muestran los términos de las primeras 10 posiciones para los 2 vectorizadores ajustados.</p>
<p>Se puede observar que <cite>v_tfidf</cite> incluye términos y bigramas, tal y como se estableció al definir esa variable.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1">## Vocabulario de un vectorizador entrenado</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">display</span><span class="p">(</span><span class="n">v_bow</span><span class="o">.</span><span class="n">vocabulario</span><span class="p">()</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">v_tfidf</span><span class="o">.</span><span class="n">vocabulario</span><span class="p">()</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
<ul class="simple">
<li>Vocabulario vectorizador BOW</li>
</ul>
<table border="1" class="docutils align-default">
<colgroup>
<col width="30%" />
<col width="70%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">posición</th>
<th class="head">palabra</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>0</td>
<td>ampliar</td>
</tr>
<tr class="row-odd"><td>1</td>
<td>cierra</td>
</tr>
<tr class="row-even"><td>2</td>
<td>complementario</td>
</tr>
<tr class="row-odd"><td>3</td>
<td>completar</td>
</tr>
<tr class="row-even"><td>4</td>
<td>común</td>
</tr>
<tr class="row-odd"><td>5</td>
<td>comúnmente</td>
</tr>
<tr class="row-even"><td>6</td>
<td>consiste</td>
</tr>
<tr class="row-odd"><td>7</td>
<td>elementos</td>
</tr>
<tr class="row-even"><td>8</td>
<td>evaluar</td>
</tr>
<tr class="row-odd"><td>9</td>
<td>finalmente</td>
</tr>
</tbody>
</table>
<ul class="simple">
<li>Vocabulario vectorizador TF-IDF</li>
</ul>
<table border="1" class="docutils align-default">
<colgroup>
<col width="30%" />
<col width="70%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">posición</th>
<th class="head">palabra</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>0</td>
<td>ampliar</td>
</tr>
<tr class="row-odd"><td>1</td>
<td>elementos</td>
</tr>
<tr class="row-even"><td>2</td>
<td>frase</td>
</tr>
<tr class="row-odd"><td>3</td>
<td>grupo</td>
</tr>
<tr class="row-even"><td>4</td>
<td>oración</td>
</tr>
<tr class="row-odd"><td>5</td>
<td>oración permite</td>
</tr>
<tr class="row-even"><td>6</td>
<td>oración siguiente</td>
</tr>
<tr class="row-odd"><td>7</td>
<td>palabras</td>
</tr>
<tr class="row-even"><td>8</td>
<td>palabras comúnmente</td>
</tr>
<tr class="row-odd"><td>9</td>
<td>permite</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="vectorizar-textos-utilizando-los-vectorizadores-entrenados">
<h3><span class="section-number">7.2.3. </span>Vectorizar textos utilizando los vectorizadores entrenados<a class="headerlink" href="#vectorizar-textos-utilizando-los-vectorizadores-entrenados" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Una vez se tiene el vectorizador ajustado, la función <cite>vectorizar</cite> permite obtener, para uno o varios textos de entrada, un arreglo (<em>array</em>) en numpy de 2 dimensiones. La cantidad de filas de este arreglo corresponde al número de textos vectorizados, y la cantidad de columnas corresponde al tamaño del vocabulario del vectorizador. El argumento <em>disperso</em>, por defecto igual a False, permite obtener la salida como una matriz dispersa, en vez de un arreglo de numpy. Esto puede traducirse en un ahorro significativo de memoria en el caso de que se tengan muchos textos y/o un vocabulario muy grande.</p>
<p>Es importante anotar que si algún texto de entrada tiene palabras que no hacen parte del vocabulario del vectorizador, estas no serán tenidas en cuenta.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">vector_bow</span> <span class="o">=</span> <span class="n">v_bow</span><span class="o">.</span><span class="n">vectorizar</span><span class="p">(</span><span class="n">texto_nuevo</span><span class="p">,</span> <span class="n">disperso</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># Salida como matriz dispersa</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vector_tfidf</span> <span class="o">=</span> <span class="n">v_tfidf</span><span class="o">.</span><span class="n">vectorizar</span><span class="p">(</span><span class="n">texto_nuevo</span><span class="p">,</span> <span class="n">disperso</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># Salida como un numpy array</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;El vector de BOW sale como una matriz dispersa:&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">vector_bow</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">--------&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;El vector de TF-IDF sale como un numpy array:&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Dimensiones de la salida:&#39;</span><span class="p">,</span> <span class="n">vector_tfidf</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">vector_tfidf</span><span class="p">)</span>

<span class="go">El vector de BOW sale como una matriz dispersa:</span>
<span class="go">  (0, 20)   1</span>
<span class="go">  (0, 24)   2</span>
<span class="go">  (0, 26)   1</span>

<span class="go">--------</span>
<span class="go">El vector de TF-IDF sale como un numpy array:</span>
<span class="go">Dimensiones de la salida: (1, 20)</span>
<span class="go">[[0.         0.         0.         0.         0.         0.</span>
<span class="go">  0.         0.         0.         0.         0.         0.</span>
<span class="go">  0.         0.         0.         0.         0.         0.</span>
<span class="go">  0.89442719 0.4472136 ]]</span>
</pre></div>
</div>
</div>
<div class="section" id="transformada-inversa-de-un-vector">
<h3><span class="section-number">7.2.4. </span>Transformada inversa de un vector<a class="headerlink" href="#transformada-inversa-de-un-vector" title="Enlazar permanentemente con este título">¶</a></h3>
<p>La función <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorFrecuencias.inversa" title="vectorizacion.VectorizadorFrecuencias.inversa"><code class="xref py py-func docutils literal notranslate"><span class="pre">inversa()</span></code></a> de la clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorFrecuencias" title="vectorizacion.VectorizadorFrecuencias"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorFrecuencias</span></code></a> permite, a partir de un vector, obtener las palabras que componen el texto representado por dicho vector.</p>
<p>Nótese que al realizar la transformada inversa se pierde el orden de las palabras. Esto se debe a que estos métodos de vectorización no tienen en cuenta el orden sino la frecuencia de aparición de cada término. Además, si un término no está en el vocabulario del vectorizador, no va a estar incluído en el vector y por lo tanto no se podrá recuperar en la transformada
inversa.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">textos_limpios</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">v_bow</span><span class="o">.</span><span class="n">inversa</span><span class="p">(</span><span class="n">v_bow</span><span class="o">.</span><span class="n">vectorizar</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">))[</span><span class="mi">0</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">textos_limpios</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">v_tfidf</span><span class="o">.</span><span class="n">inversa</span><span class="p">(</span><span class="n">v_tfidf</span><span class="o">.</span><span class="n">vectorizar</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">))[</span><span class="mi">2</span><span class="p">])</span>

<span class="go">primer texto prueba vectorización elementos</span>
<span class="go">[&#39;elementos&#39; &#39;primer&#39; &#39;prueba&#39; &#39;texto&#39; &#39;vectorización&#39;]</span>
<span class="go">tercera frase consiste texto complementario palabras comúnmente utilizadas</span>
<span class="go">[&#39;frase&#39; &#39;palabras&#39; &#39;palabras comúnmente&#39; &#39;texto&#39;]</span>
</pre></div>
</div>
</div>
<div class="section" id="cargar-un-vectorizador-ajustado-previamente">
<h3><span class="section-number">7.2.5. </span>Cargar un vectorizador ajustado previamente<a class="headerlink" href="#cargar-un-vectorizador-ajustado-previamente" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Previamente vimos cómo se puede guardar un vectorizador ajustado, por medio del parámetro <em>archivo_salida</em> de la función <cite>ajustar</cite>. Este vectorizador ya ajustado se puede cargar y utilizar, al momento de definir un nuevo objeto de la clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorFrecuencias" title="vectorizacion.VectorizadorFrecuencias"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorFrecuencias</span></code></a>. Para cargar un vectorizador ajustado previamente se debe utilizar el parámetro <em>archivo_modelo</em>, especificando dónde está el archivo con el vectorizador ya ajustado. Al usar esta opción, los demás parámetros de inicialización no serán tenidos en cuenta, pues esos parámetros se tomarán del vectorizador cargado.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">v_bow_2</span> <span class="o">=</span> <span class="n">VectorizadorFrecuencias</span><span class="p">(</span><span class="n">archivo_modelo</span><span class="o">=</span><span class="s1">&#39;salida/v_bow.pk&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_tfidf_2</span> <span class="o">=</span> <span class="n">VectorizadorFrecuencias</span><span class="p">(</span><span class="n">archivo_modelo</span><span class="o">=</span><span class="s1">&#39;salida/v_tfidf.pk&#39;</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Se vectoriza el mismo texto con los vectorizadores cargados</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vector_bow_2</span> <span class="o">=</span> <span class="n">v_bow_2</span><span class="o">.</span><span class="n">vectorizar</span><span class="p">(</span><span class="n">texto_nuevo</span><span class="p">,</span> <span class="n">disperso</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># Salida como matriz dispersa</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vector_tfidf_2</span> <span class="o">=</span> <span class="n">v_tfidf_2</span><span class="o">.</span><span class="n">vectorizar</span><span class="p">(</span><span class="n">texto_nuevo</span><span class="p">,</span> <span class="n">disperso</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># Salida como un numpy array</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Se comprueba que los vectores resultantes sean iguales</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">vector_bow</span> <span class="o">==</span> <span class="n">vector_bow_2</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">vector_tfidf</span> <span class="o">==</span> <span class="n">vector_tfidf_2</span><span class="p">))</span>

<span class="go">True</span>
<span class="go">True</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="vectorizacion-por-medio-de-hashing">
<h2><span class="section-number">7.3. </span>Vectorización por medio de <em>Hashing</em><a class="headerlink" href="#vectorizacion-por-medio-de-hashing" title="Enlazar permanentemente con este título">¶</a></h2>
<p>La clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorHash" title="vectorizacion.VectorizadorHash"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorHash</span></code></a> utiliza el <em>hashing trick</em> para determinar directamente (sin necesidad de ajustar sobre un corpus) la posición de cada término de un texto dentro de un vector numérico. Esta técnica es rápida y ligera en memoria, pues no requiere aprender ni guardar un vocabulario. Esto también tiene algunas desventajas; por ejemplo, a partir de un vector no se puede aplicar una transformada inversa para conocer qué palabras contenía el texto.</p>
<p>Adicionalmente, para muchos textos, o textos muy grandes, existe la posibilidad de que se presenten “colisiones”. Una colisión se da cuando el vectorizador representa de la misma manera a dos términos distinitos, lo cual introduce ambiguedad en la vectorización y disminuye la calidad de la representación numérica de los textos. Para evitar este problema, se puede configurar el objeto de clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorHash" title="vectorizacion.VectorizadorHash"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorHash</span></code></a> para que tenga muchos más elementos (por medio del parámetro <em>n_elementos</em>) a medida que se trabaja con textos de mayor longitud y vocabulario.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1">## Inicializar el vectorizador</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># En este caso se define que los vectores tendrán 50 elementos</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_hash</span> <span class="o">=</span> <span class="n">VectorizadorHash</span><span class="p">(</span><span class="n">n_elementos</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1">## Aplicar el vectorizador directamente a los textos (no hace falta ajustar antes)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vectores_prueba</span> <span class="o">=</span> <span class="n">v_hash</span><span class="o">.</span><span class="n">vectorizar</span><span class="p">(</span><span class="n">textos_prueba</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dimensiones del grupo de vectores:&quot;</span><span class="p">,</span> <span class="n">vectores_prueba</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># El valor de cada elemento será proporcional a la frecuencia de aparición de un término en el texto</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vector_nuevo</span> <span class="o">=</span> <span class="n">v_hash</span><span class="o">.</span><span class="n">vectorizar</span><span class="p">(</span><span class="n">texto_nuevo</span><span class="p">,</span> <span class="n">disperso</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;----------&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dimensiones del vector:&quot;</span><span class="p">,</span> <span class="n">vector_nuevo</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">vector_nuevo</span><span class="p">)</span>

<span class="go">Dimensiones del grupo de vectores: (6, 50)</span>
<span class="go">----------</span>
<span class="go">Dimensiones del vector: (1, 50)</span>
<span class="go">[[ 0.   0.  -0.2  0.   0.   0.   0.2  0.   0.2  0.   0.   0.   0.   0.</span>
<span class="go">   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.4 -0.2 -0.2</span>
<span class="go">   0.   0.   0.   0.   0.   0.   0.  -0.2  0.   0.  -0.2  0.   0.  -0.4</span>
<span class="go">   0.   0.   0.6  0.   0.   0.2  0.   0. ]]</span>
</pre></div>
</div>
</div>
<div class="section" id="vectorizacion-utilizando-word-embeddings-word2vec">
<h2><span class="section-number">7.4. </span>Vectorización utilizando <em>word embeddings</em> - Word2Vec<a class="headerlink" href="#vectorizacion-utilizando-word-embeddings-word2vec" title="Enlazar permanentemente con este título">¶</a></h2>
<p>La clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorWord2Vec" title="vectorizacion.VectorizadorWord2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorWord2Vec</span></code></a> utiliza por debajo las funcionalidades de la librería
<a class="reference external" href="https://spacy.io/" target="_blank">spaCy</a> para cargar <em>embeddings</em>, o representaciones vectoriales densas, de palabras en diferentes idiomas. Estas <em>embeddings</em> son representaciones de 300 elementos para cada palabra que exista en el diccionario del modelo, y ya han sido previamente entrenadas sobre un corpus de texto muy grande, utilizando de técnicas como <em>Word2Vec</em> y <em>GloVe</em>.</p>
<p>La clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorWord2Vec" title="vectorizacion.VectorizadorWord2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorWord2Vec</span></code></a> permite acceder a y utilizar estas representaciones ya entrenadas que, a diferencia de los vectores basados en frecuencias, permiten a través del entrenamiento previo capturar información del contexto de las palabras. De esta manera, las representaciones densas de las palabras “hombre” y “niño” van a ser similares entre sí en ese espacio de 300 dimensiones, mientas que las palabras “hombre” y “cuchara” van a estar más alejadas.</p>
<div class="section" id="inicializar-y-aplicar-el-vectorizador">
<h3><span class="section-number">7.4.1. </span>Inicializar y aplicar el vectorizador<a class="headerlink" href="#inicializar-y-aplicar-el-vectorizador" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Al definir un objeto de la clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorWord2Vec" title="vectorizacion.VectorizadorWord2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorWord2Vec</span></code></a> es necesario definir el lenguaje y el tamaño del modelo que se desea utilizar. De manera similar al caso de lematización, en este caso spaCy tiene modelos de varios tamaños para cada lenguaje. Entre más grande sea el modelo, este contará con vectores para un vocabulario más grande. Los modelos de spaCy que soportan la vectorización son el mediano (“md”) y el grande (“lg”).</p>
<p>Dado que se carga un modelo previamente entrenado, no es necesario ajustar este vectorizador. Al igual que con el <cite>VectorizadorHash</cite>, los objetos de clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorWord2Vec" title="vectorizacion.VectorizadorWord2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorWord2Vec</span></code></a> pueden ser aplicados directamente a una palabra o texto de entrada para obtener su vector. Cuando el texto de entrada tiene dos o más palabras, la función <cite>vectorizar</cite> obtendrá el vector de cada palabra que compone el texto, y luego calculará el promedio de todos los vectores para obtener un único vector de salida.</p>
<div class="admonition note">
<p class="first admonition-title">Nota</p>
<p class="last">La primera vez que se utilice una combinación particular de lenguaje + tamaño, la librería descargará el modelo correspondiente en el computador del usuario. Para poder usar este modelo, se debe reiniciar la sesión de Python y correr la función de nuevo.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1">## Inicializar el vectorizador</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_word2vec</span> <span class="o">=</span> <span class="n">VectorizadorWord2Vec</span><span class="p">()</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">## Vectorizar textos utilizando el vectorizador</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vector</span> <span class="o">=</span> <span class="n">v_word2vec</span><span class="o">.</span><span class="n">vectorizar</span><span class="p">(</span><span class="n">texto_nuevo</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dimensiones del vector:&quot;</span><span class="p">,</span> <span class="n">vector</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Primeros 10 elementos del vector:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">vector</span><span class="p">[</span><span class="mi">0</span><span class="p">,:</span><span class="mi">10</span><span class="p">])</span>

<span class="go">Dimensiones del vector: (1, 300)</span>
<span class="go">Primeros 10 elementos del vector:</span>
<span class="go"> [ 0.3364028   0.7943878  -0.5733206   1.1075957   1.1357956  -1.3824669</span>
<span class="go">  0.53068686  0.662284   -0.33499992  0.22997226]</span>
</pre></div>
</div>
</div>
<div class="section" id="textos-con-palabras-desconocidas-no-incluidas-en-el-modelo">
<h3><span class="section-number">7.4.2. </span>Textos con palabras desconocidas (no incluídas en el modelo)<a class="headerlink" href="#textos-con-palabras-desconocidas-no-incluidas-en-el-modelo" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Como se mencionó en la sección anterior, un texto se vectoriza sacando el promedio de los vectores de cada palabra. Por grande que sea el vocabulario del modelo pre-entrenado que se utiliza, es posible que un nuevo texto contenga palabras que no se encuentran en el vocabulario del modelo. En este caso, el método <cite>vectorizar</cite> del objeto de clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorWord2Vec" title="vectorizacion.VectorizadorWord2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorWord2Vec</span></code></a> puede manejar las palabras desconocidas de dos formas distintas.</p>
<p>El argumento booleano <em>quitar_desconocidas</em> en el método <cite>vectorizar</cite>, cuando se hace igual a True, hará que no se tengan en cuenta las palabras que no están incluídas en el modelo. De esta manera, el vector del texto será el promedio de solamente los vectores de palabras que están presentes en el vocabulario del modelo. Cuando este argumento es False (valor por defecto), para cada palabra desconocida se incluirá un vector de solo ceros, lo que afectará el vector promedio resultante.</p>
<p>A continuación se hace la vectorización de 2 textos distintos. En el primer texto todas las palabras hacen parte del vocabulario del modelo, por lo que el valor del parámetro <em>quitar_desconocidas</em> no va a afectar el vector de salida. Por otro lado, el segundo texto tiene 3 palabras desconocidas. En este caso, los valores del vector resultante van a ser ligeramente menores si se utiliza <em>quitar_desconocidas=False</em>, pues los vectores de solo ceros (correspondientes a las palabras desconocidas) afectarán el promedio del vector de salida.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">texto_1</span> <span class="o">=</span> <span class="s1">&#39;En este texto todas las palabras son conocidas, por lo que los resultados deberían ser iguales&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">texto_2</span> <span class="o">=</span> <span class="s1">&#39;En este texto hay asfafgf términos desconocidos FGs&lt;g gsi&lt;gi&lt;sbf&#39;</span>

<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="n">texto_1</span><span class="p">,</span> <span class="n">texto_2</span><span class="p">]):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">------------------&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Texto </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">:&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;&quot;</span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s1">&quot;&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">v1</span> <span class="o">=</span> <span class="n">v_word2vec</span><span class="o">.</span><span class="n">vectorizar</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">quitar_desconocidas</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">v2</span> <span class="o">=</span> <span class="n">v_word2vec</span><span class="o">.</span><span class="n">vectorizar</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">quitar_desconocidas</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Diferencia promedio: </span><span class="si">{</span><span class="p">(</span><span class="n">v1</span> <span class="o">-</span> <span class="n">v2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="go">------------------</span>
<span class="go">Texto 1:</span>
<span class="go">&quot;En este texto todas las palabras son conocidas, por lo que los resultados deberían ser iguales&quot;</span>
<span class="go">Diferencia promedio: 0.0</span>

<span class="go">------------------</span>
<span class="go">Texto 2:</span>
<span class="go">&quot;En este texto hay asfafgf términos desconocidos FGs&lt;g gsi&lt;gi&lt;sbf&quot;</span>
<span class="go">Diferencia promedio: -0.017988834530115128</span>
</pre></div>
</div>
</div>
<div class="section" id="obtener-palabras-y-vectores-de-un-texto">
<h3><span class="section-number">7.4.3. </span>Obtener palabras y vectores de un texto<a class="headerlink" href="#obtener-palabras-y-vectores-de-un-texto" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Si se desea, es posible obtener los vectores correspondientes a las palabras (incluidas en el modelo) que componen un texto. Esto se puede hacer mediante el método <cite>vectores_palabras</cite>, que puede devolver un DataFrame de Pandas o un diccionario de Python con cada palabra del texto y su correspondiente vector.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">df_palabras</span> <span class="o">=</span> <span class="n">v_word2vec</span><span class="o">.</span><span class="n">vectores_palabras</span><span class="p">(</span><span class="n">texto_nuevo</span><span class="p">,</span> <span class="n">tipo</span><span class="o">=</span><span class="s1">&#39;dataframe&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dict_palabras</span> <span class="o">=</span> <span class="n">v_word2vec</span><span class="o">.</span><span class="n">vectores_palabras</span><span class="p">(</span><span class="n">texto_nuevo</span><span class="p">,</span> <span class="n">tipo</span><span class="o">=</span><span class="s1">&#39;diccionario&#39;</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">df_palabras</span>
</pre></div>
</div>
<table border="1" class="docutils align-default">
<colgroup>
<col width="3%" />
<col width="7%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="2%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">index</th>
<th class="head">palabra</th>
<th class="head">x_1</th>
<th class="head">x_2</th>
<th class="head">x_3</th>
<th class="head">x_4</th>
<th class="head">x_5</th>
<th class="head">x_6</th>
<th class="head">x_7</th>
<th class="head">x_8</th>
<th class="head">x_9</th>
<th class="head">…</th>
<th class="head">x_291</th>
<th class="head">x_292</th>
<th class="head">x_293</th>
<th class="head">x_294</th>
<th class="head">x_295</th>
<th class="head">x_296</th>
<th class="head">x_297</th>
<th class="head">x_298</th>
<th class="head">x_299</th>
<th class="head">x_300</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>0</td>
<td>hola</td>
<td>2.02740</td>
<td>-1.274000</td>
<td>-1.36240</td>
<td>1.66310</td>
<td>0.923830</td>
<td>-0.150770</td>
<td>0.345830</td>
<td>1.36940</td>
<td>0.61444</td>
<td>…</td>
<td>1.35750</td>
<td>0.38467</td>
<td>0.505280</td>
<td>0.858590</td>
<td>1.36380</td>
<td>1.527900</td>
<td>-1.262800</td>
<td>0.82706</td>
<td>-0.85570</td>
<td>1.188800</td>
</tr>
<tr class="row-odd"><td>1</td>
<td>,</td>
<td>1.34940</td>
<td>2.957500</td>
<td>-0.60029</td>
<td>-1.40760</td>
<td>1.909200</td>
<td>-0.285360</td>
<td>0.581940</td>
<td>2.43280</td>
<td>-1.59410</td>
<td>…</td>
<td>-1.31810</td>
<td>0.24310</td>
<td>0.353180</td>
<td>0.727520</td>
<td>2.83400</td>
<td>-0.051198</td>
<td>3.489500</td>
<td>1.34580</td>
<td>-2.10970</td>
<td>-0.455530</td>
</tr>
<tr class="row-even"><td>2</td>
<td>este</td>
<td>-1.18150</td>
<td>4.074300</td>
<td>-3.72130</td>
<td>5.79750</td>
<td>-1.925600</td>
<td>-1.465900</td>
<td>-1.253400</td>
<td>-0.48991</td>
<td>-1.67700</td>
<td>…</td>
<td>-0.38054</td>
<td>-1.09720</td>
<td>-0.531430</td>
<td>-3.957000</td>
<td>-0.24913</td>
<td>-1.922400</td>
<td>2.318000</td>
<td>1.02020</td>
<td>2.88400</td>
<td>1.210200</td>
</tr>
<tr class="row-odd"><td>3</td>
<td>es</td>
<td>-5.67930</td>
<td>-1.851200</td>
<td>-6.46630</td>
<td>-1.57010</td>
<td>-1.770900</td>
<td>-4.910200</td>
<td>0.362290</td>
<td>5.48250</td>
<td>-1.92520</td>
<td>…</td>
<td>-7.98300</td>
<td>-1.78740</td>
<td>-7.126600</td>
<td>-1.653700</td>
<td>2.02190</td>
<td>3.560900</td>
<td>-1.280100</td>
<td>-0.48058</td>
<td>0.65105</td>
<td>-2.964400</td>
</tr>
<tr class="row-even"><td>4</td>
<td>un</td>
<td>0.89790</td>
<td>5.847700</td>
<td>-8.07040</td>
<td>8.84070</td>
<td>-5.782700</td>
<td>4.143200</td>
<td>-0.571410</td>
<td>-0.40119</td>
<td>-4.93190</td>
<td>…</td>
<td>3.62440</td>
<td>-3.06400</td>
<td>-0.009281</td>
<td>-8.710900</td>
<td>2.13160</td>
<td>-6.541200</td>
<td>0.267060</td>
<td>3.80520</td>
<td>6.24080</td>
<td>2.837600</td>
</tr>
<tr class="row-odd"><td>5</td>
<td>texto</td>
<td>-1.28030</td>
<td>0.235800</td>
<td>-1.87390</td>
<td>0.90060</td>
<td>-0.246720</td>
<td>-2.607000</td>
<td>0.063837</td>
<td>5.56190</td>
<td>0.33668</td>
<td>…</td>
<td>1.07400</td>
<td>2.13570</td>
<td>-5.215400</td>
<td>-2.547800</td>
<td>-3.13900</td>
<td>-0.193810</td>
<td>-1.107400</td>
<td>0.75978</td>
<td>0.73341</td>
<td>0.052985</td>
</tr>
<tr class="row-even"><td>6</td>
<td>de</td>
<td>0.38853</td>
<td>0.099683</td>
<td>5.99970</td>
<td>-0.83435</td>
<td>3.742600</td>
<td>-1.322600</td>
<td>3.394800</td>
<td>-2.84590</td>
<td>3.28950</td>
<td>…</td>
<td>-7.32290</td>
<td>-1.18470</td>
<td>0.010714</td>
<td>-3.567100</td>
<td>0.70618</td>
<td>-1.429100</td>
<td>-1.557600</td>
<td>2.12330</td>
<td>0.92697</td>
<td>1.500900</td>
</tr>
<tr class="row-odd"><td>7</td>
<td>prueba</td>
<td>1.43410</td>
<td>1.177200</td>
<td>-0.87280</td>
<td>0.85857</td>
<td>-3.028900</td>
<td>-1.197400</td>
<td>0.492080</td>
<td>1.47920</td>
<td>-2.09090</td>
<td>…</td>
<td>3.26440</td>
<td>0.39533</td>
<td>1.870100</td>
<td>-1.900300</td>
<td>2.28250</td>
<td>-0.399500</td>
<td>-0.059084</td>
<td>0.11512</td>
<td>-1.33580</td>
<td>-1.433700</td>
</tr>
<tr class="row-even"><td>8</td>
<td>.</td>
<td>1.65170</td>
<td>-1.963400</td>
<td>-0.60317</td>
<td>-1.44970</td>
<td>-4.645600</td>
<td>-2.654800</td>
<td>1.787100</td>
<td>2.00860</td>
<td>2.55950</td>
<td>…</td>
<td>-2.95930</td>
<td>0.74480</td>
<td>2.189800</td>
<td>0.798260</td>
<td>2.64470</td>
<td>-1.984700</td>
<td>-3.354100</td>
<td>-0.39062</td>
<td>-1.83260</td>
<td>-3.034700</td>
</tr>
<tr class="row-odd"><td>9</td>
<td>Se</td>
<td>3.44230</td>
<td>3.517600</td>
<td>-0.98323</td>
<td>9.61150</td>
<td>21.457001</td>
<td>1.370800</td>
<td>9.016600</td>
<td>-7.84960</td>
<td>-6.47540</td>
<td>…</td>
<td>1.33140</td>
<td>-9.96640</td>
<td>-2.405100</td>
<td>6.446200</td>
<td>-8.91220</td>
<td>11.387000</td>
<td>1.724500</td>
<td>-1.94600</td>
<td>-2.71580</td>
<td>2.913400</td>
</tr>
<tr class="row-even"><td>10</td>
<td>desea</td>
<td>-4.29940</td>
<td>1.219600</td>
<td>0.87215</td>
<td>-0.35671</td>
<td>0.492250</td>
<td>-1.972400</td>
<td>-0.203840</td>
<td>7.01900</td>
<td>3.22810</td>
<td>…</td>
<td>1.99170</td>
<td>-3.23270</td>
<td>-1.868300</td>
<td>-1.517700</td>
<td>0.66831</td>
<td>0.154560</td>
<td>-3.252000</td>
<td>0.28146</td>
<td>1.07270</td>
<td>-1.384100</td>
</tr>
<tr class="row-odd"><td>11</td>
<td>aplicar</td>
<td>-1.40740</td>
<td>1.299100</td>
<td>2.13120</td>
<td>0.30753</td>
<td>-0.928430</td>
<td>-0.020372</td>
<td>-2.409200</td>
<td>0.80072</td>
<td>-1.60250</td>
<td>…</td>
<td>-0.57665</td>
<td>2.95660</td>
<td>0.028279</td>
<td>-0.052178</td>
<td>-2.21730</td>
<td>-1.184800</td>
<td>-1.614600</td>
<td>-0.92878</td>
<td>-2.93960</td>
<td>-1.921600</td>
</tr>
<tr class="row-even"><td>12</td>
<td>la</td>
<td>4.81890</td>
<td>-1.975100</td>
<td>3.98690</td>
<td>-9.48320</td>
<td>14.446000</td>
<td>-7.265700</td>
<td>2.178200</td>
<td>-8.03830</td>
<td>6.41720</td>
<td>…</td>
<td>-0.94738</td>
<td>2.05770</td>
<td>-5.546100</td>
<td>5.935200</td>
<td>-0.55970</td>
<td>2.730500</td>
<td>-4.170200</td>
<td>-0.59639</td>
<td>0.24436</td>
<td>2.381200</td>
</tr>
<tr class="row-odd"><td>13</td>
<td>vectorización</td>
<td>-0.28528</td>
<td>1.867000</td>
<td>0.71944</td>
<td>-0.46232</td>
<td>0.076307</td>
<td>-2.183900</td>
<td>-1.985400</td>
<td>1.27820</td>
<td>-1.78520</td>
<td>…</td>
<td>0.90734</td>
<td>1.39140</td>
<td>-2.335200</td>
<td>1.182900</td>
<td>-1.13460</td>
<td>-0.324270</td>
<td>0.553240</td>
<td>-0.17405</td>
<td>-1.53170</td>
<td>-1.541200</td>
</tr>
<tr class="row-even"><td>14</td>
<td>en</td>
<td>4.98830</td>
<td>-3.279500</td>
<td>6.72300</td>
<td>2.27280</td>
<td>2.543900</td>
<td>2.365700</td>
<td>-2.844600</td>
<td>-2.96690</td>
<td>-1.61240</td>
<td>…</td>
<td>-1.73490</td>
<td>-0.80675</td>
<td>1.798400</td>
<td>1.553700</td>
<td>9.86970</td>
<td>0.683280</td>
<td>3.565700</td>
<td>3.63670</td>
<td>4.76150</td>
<td>-0.695040</td>
</tr>
<tr class="row-odd"><td>15</td>
<td>este</td>
<td>-1.18150</td>
<td>4.074300</td>
<td>-3.72130</td>
<td>5.79750</td>
<td>-1.925600</td>
<td>-1.465900</td>
<td>-1.253400</td>
<td>-0.48991</td>
<td>-1.67700</td>
<td>…</td>
<td>-0.38054</td>
<td>-1.09720</td>
<td>-0.531430</td>
<td>-3.957000</td>
<td>-0.24913</td>
<td>-1.922400</td>
<td>2.318000</td>
<td>1.02020</td>
<td>2.88400</td>
<td>1.210200</td>
</tr>
<tr class="row-even"><td>16</td>
<td>texto</td>
<td>-1.28030</td>
<td>0.235800</td>
<td>-1.87390</td>
<td>0.90060</td>
<td>-0.246720</td>
<td>-2.607000</td>
<td>0.063837</td>
<td>5.56190</td>
<td>0.33668</td>
<td>…</td>
<td>1.07400</td>
<td>2.13570</td>
<td>-5.215400</td>
<td>-2.547800</td>
<td>-3.13900</td>
<td>-0.193810</td>
<td>-1.107400</td>
<td>0.75978</td>
<td>0.73341</td>
<td>0.052985</td>
</tr>
<tr class="row-odd"><td>17</td>
<td>.</td>
<td>1.65170</td>
<td>-1.963400</td>
<td>-0.60317</td>
<td>-1.44970</td>
<td>-4.645600</td>
<td>-2.654800</td>
<td>1.787100</td>
<td>2.00860</td>
<td>2.55950</td>
<td>…</td>
<td>-2.95930</td>
<td>0.74480</td>
<td>2.189800</td>
<td>0.798260</td>
<td>2.64470</td>
<td>-1.984700</td>
<td>-3.354100</td>
<td>-0.39062</td>
<td>-1.83260</td>
<td>-3.034700</td>
</tr>
</tbody>
</table>
<p>18 rows × 301 columns</p>
</div>
<div class="section" id="calcular-similitudes-entre-textos">
<h3><span class="section-number">7.4.4. </span>Calcular similitudes entre textos<a class="headerlink" href="#calcular-similitudes-entre-textos" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Finalmente, y aunque hay un módulo de <strong>ConTexto</strong> dedicado exclusivamente al cálculo de distancias y similitudes entre textos, los objetos de la clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorWord2Vec" title="vectorizacion.VectorizadorWord2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorWord2Vec</span></code></a> cuentan con la función <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorWord2Vec.similitud_textos" title="vectorizacion.VectorizadorWord2Vec.similitud_textos"><code class="xref py py-func docutils literal notranslate"><span class="pre">similitud_textos()</span></code></a>, para medir la similitud entre dos palabras o textos.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1">## 3.5 Similitudes entre textos</span>
<span class="gp">&gt;&gt;&gt; </span><span class="sd">&#39;&#39;&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="sd">Esta función aprovecha las facilidades de la librería Spacy para medir la</span>
<span class="gp">&gt;&gt;&gt; </span><span class="sd">similaridad entre 2 palabras o textos.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="sd">&#39;&#39;&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t1</span> <span class="o">=</span> <span class="s1">&#39;los perros y los gatos suelen pelear mucho.&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t2</span> <span class="o">=</span> <span class="s1">&#39;caninos y felinos entran en disputas con frecuencia.&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t3</span> <span class="o">=</span> <span class="s1">&#39;este tercer texto habla sobre un tema distinto a los otros dos&#39;</span>

<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="p">[</span><span class="n">t2</span><span class="p">,</span> <span class="n">t3</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">j</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>            <span class="n">similitud</span> <span class="o">=</span> <span class="n">v_word2vec</span><span class="o">.</span><span class="n">similitud_textos</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-----------------------&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Texto 1: </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Texto 2: </span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Similitud entre textos: </span><span class="si">{</span><span class="n">similitud</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="go">-----------------------</span>
<span class="go">Texto 1: los perros y los gatos suelen pelear mucho.</span>
<span class="go">Texto 2: caninos y felinos entran en disputas con frecuencia.</span>
<span class="go">Similitud entre textos: 0.6875509408308378</span>
<span class="go">-----------------------</span>
<span class="go">Texto 1: los perros y los gatos suelen pelear mucho.</span>
<span class="go">Texto 2: este tercer texto habla sobre un tema distinto a los otros dos</span>
<span class="go">Similitud entre textos: 0.5168476867313971</span>
<span class="go">-----------------------</span>
<span class="go">Texto 1: caninos y felinos entran en disputas con frecuencia.</span>
<span class="go">Texto 2: este tercer texto habla sobre un tema distinto a los otros dos</span>
<span class="go">Similitud entre textos: 0.4299091504956323</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="vectorizacion-utilizando-document-embeddings-doc2vec">
<h2><span class="section-number">7.5. </span>Vectorización utilizando <em>document embeddings</em> - Doc2Vec<a class="headerlink" href="#vectorizacion-utilizando-document-embeddings-doc2vec" title="Enlazar permanentemente con este título">¶</a></h2>
<p>La clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorDoc2Vec" title="vectorizacion.VectorizadorDoc2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorDoc2Vec</span></code></a> utiliza por debajo las funcionalidades de la librería
<a class="reference external" href="https://radimrehurek.com/gensim/" target="_blank">Gensim</a> para entrenar un vectorizador en un corpus o conjunto de textos, de manera que sea capaz de representar documentos mediante <em>embeddings</em>, o representaciones vectoriales densas. Estas <em>embeddings</em> son representaciones de un número de elementos definido por el usuario. Tanto para entrenar el vectorizador como para utilizarlo posteriormente, es necesario hacer un procesamiento sobre los textos de entrada. Las funciones internas de la clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorDoc2Vec" title="vectorizacion.VectorizadorDoc2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorDoc2Vec</span></code></a> se encargan de este procesamiento.</p>
<div class="section" id="inicializar-y-entrenar-el-vectorizador">
<h3><span class="section-number">7.5.1. </span>Inicializar y entrenar el vectorizador<a class="headerlink" href="#inicializar-y-entrenar-el-vectorizador" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Al igual que los vectorizadores basados en frecuencias (<a class="reference external" href="07_vectorizacion_de_textos.html#vectorizaciones-por-frecuencia-de-terminos" target="_blank">ver sección</a>) , los objetos de clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorDoc2Vec" title="vectorizacion.VectorizadorDoc2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorDoc2Vec</span></code></a> deben ser entrenados o ajustados sobre un corpus de textos. El primer paso es inicializar el objeto del vectorizador; para esto, se deben definir los siguientes parámetros:</p>
<ul class="simple">
<li>Número de elementos que tendrán los vectores</li>
<li>Frecuencia mínima que debe tener cada término en el corpus para ser tenido en cuenta en el modelo. Esto se utiliza para evitar que términos muy poco frecuentes afecten el entrenamiento.</li>
<li>Número de iteraciones (épocas) que realiza la red neuronal al entrenar el modelo.</li>
</ul>
<p>En este ejemplo el corpus de entrenamiento es muy pequeño (5 textos cortos), y ninguna palabra cumple con el parámetro <em>minima_cuenta=5</em> (valor por defecto). Esto puede generar errores, por lo que en este caso se cambia este parámetro a 1 (valor mínimo).</p>
<p>Adicionalmente, al entrenar el vectorizador, por medio del método <cite>entrenar_modelo</cite>, se utiliza el parámetro <em>archivo_salida</em> (opcional) para guardar el modelo entrenado en la ubicación establecida por el usuario.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1">## Inicializar el vectorizador</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Se configura para que tenga 100 elementos y se entrene por 25 épocas</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_doc2vec</span> <span class="o">=</span> <span class="n">VectorizadorDoc2Vec</span><span class="p">(</span><span class="n">n_elementos</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">epocas</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">minima_cuenta</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1">## Entrenar el modelo en un corpus</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_doc2vec</span><span class="o">.</span><span class="n">entrenar_modelo</span><span class="p">(</span><span class="n">textos_limpios</span><span class="p">,</span> <span class="n">archivo_salida</span><span class="o">=</span><span class="s1">&#39;salida/v_doc2vec.pk&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="vectorizar-textos-utilizando-el-vectorizador">
<h3><span class="section-number">7.5.2. </span>Vectorizar textos utilizando el vectorizador<a class="headerlink" href="#vectorizar-textos-utilizando-el-vectorizador" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Al igual que con los otros vectorizadores, el método <cite>vectorizar</cite> acepta un texto o una lista de textos como entrada, y devuelve un arreglo numpy de dos dimensiones con los vectores generados. Normalmente, esta operación de vectorización puede producir diferentes vectores para un mismo texto de entrada, que aunque tienen valores distintos son similares entre sí en el espacio <em>n_elementos</em>-dimensional.</p>
<p>Sin embargo, la clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorDoc2Vec" title="vectorizacion.VectorizadorDoc2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorDoc2Vec</span></code></a> cuenta con una semilla para asegurar que siempre se obtenga el mismo vector para el mismo texto de entrada.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">vector</span> <span class="o">=</span> <span class="n">v_doc2vec</span><span class="o">.</span><span class="n">vectorizar</span><span class="p">(</span><span class="n">texto_nuevo</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dimensiones del vector:&quot;</span><span class="p">,</span> <span class="n">vector</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Primeros 10 elementos del vector:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">vector</span><span class="p">[</span><span class="mi">0</span><span class="p">,:</span><span class="mi">10</span><span class="p">])</span>

<span class="go">Dimensiones del vector: (1, 100)</span>
<span class="go">Primeros 10 elementos del vector:</span>
<span class="go"> [ 0.00011651 -0.00289909 -0.00298333 -0.00355879  0.00197437  0.00171644</span>
<span class="go">  0.00276862  0.00240826  0.00056794 -0.00210888]</span>
</pre></div>
</div>
</div>
<div class="section" id="cargar-un-vectorizador-entrenado-previamente">
<h3><span class="section-number">7.5.3. </span>Cargar un vectorizador entrenado previamente<a class="headerlink" href="#cargar-un-vectorizador-entrenado-previamente" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Previamente vimos cómo se puede guardar un vectorizador entrenado, por medio del parámetro <em>archivo_salida</em> de la función <cite>entrenar_modelo</cite>. Este vectorizador ya ajustado se puede cargar y utilizar, al momento de definir un nuevo objeto de la clase <a class="reference internal" href="../funciones/vectorizacion.html#vectorizacion.VectorizadorDoc2Vec" title="vectorizacion.VectorizadorDoc2Vec"><code class="xref py py-class docutils literal notranslate"><span class="pre">VectorizadorDoc2Vec</span></code></a>. Para cargar un vectorizador ajustado previamente se debe utilizar el parámetro <em>archivo_modelo</em>, especificando dónde está el archivo con el vectorizador ya ajustado. Al usar esta opción, los demás parámetros de inicialización no serán tenidos en cuenta, pues esos parámetros se tomarán del vectorizador cargado.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1">## Cargar un vectorizador entrenado previamente</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v_doc2vec_2</span> <span class="o">=</span> <span class="n">VectorizadorDoc2Vec</span><span class="p">(</span><span class="n">archivo_modelo</span><span class="o">=</span><span class="s1">&#39;salida/v_doc2vec.pk&#39;</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Se vectoriza el mismo texto con el vectorizador cargado</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vector_2</span> <span class="o">=</span> <span class="n">v_doc2vec_2</span><span class="o">.</span><span class="n">vectorizar</span><span class="p">(</span><span class="n">texto_nuevo</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Se comprueba que ambos vectores resultantes sean iguales</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">vector</span> <span class="o">==</span> <span class="n">vector_2</span><span class="p">)</span>

<span class="go">True</span>
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="08_comparacion_de_textos.html" class="btn btn-neutral float-right" title="8. Comparación de textos" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="06_stemming_de_textos.html" class="btn btn-neutral float-left" title="6. Stemming de textos" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Derechos de autor 2021, UCD - DNP.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Otras versiones</span>
        v: latest
      

    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Ramas</dt>
          <dd><a href="07_vectorizacion_de_textos.html">latest</a></dd>        
        
    </dl>    

  </div>
</div>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>